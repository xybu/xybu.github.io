[{"iconClass":"fa-folder","objectID":"98959b82e8c980577f4bfcc7f09bb3be","title":"Hack","type":"category","url":"/categories/hack"},{"iconClass":"fa-folder","objectID":"57518b970c3ad9783f50e4f7faf4d104","title":"Project","type":"category","url":"/categories/project"},{"iconClass":"fa-folder","objectID":"158868502ea624c5c368beba928c8761","title":"Resource","type":"category","url":"/categories/resource"},{"iconClass":"fa-folder","objectID":"672ce43db1df8c44b2d0074109238ab3","title":"Troubleshooting","type":"category","url":"/categories/troubleshooting"},{"iconClass":"fa-folder","objectID":"ba36f357fb72e00bb028bc6a48118cb8","title":"Tutorial","type":"category","url":"/categories/tutorial"},{"iconClass":"fa-user","objectID":"85a651dfcb7bd699bcdb9ee7c0ec6077","title":"Andy grove","type":"author","url":"/author/andy-grove"},{"iconClass":"fa-user","objectID":"96fdec6a396bfafa514e0d9d65b2af2d","title":"Xbu","type":"author","url":"/author/xbu"},{"iconClass":"fa-tag","objectID":"03dd43b8ad681c4161f0b5655559a152","title":"App","type":"tag","url":"/tags/app"},{"iconClass":"fa-tag","objectID":"8c1229233593d87158f9d23824cb36d1","title":"Autograding","type":"tag","url":"/tags/autograding"},{"iconClass":"fa-tag","objectID":"4f2a1ebd2d3fdca3c274866a8aa217c4","title":"Benchmark","type":"tag","url":"/tags/benchmark"},{"iconClass":"fa-tag","objectID":"f590fb44b8bc1a5422148b128717c5a5","title":"C","type":"tag","url":"/tags/c"},{"iconClass":"fa-tag","objectID":"0023ce917e7fbc3e5516229386608776","title":"Comparison","type":"tag","url":"/tags/comparison"},{"iconClass":"fa-tag","objectID":"36d9a99168ad7abca64faf718c4e452b","title":"Csharp","type":"tag","url":"/tags/csharp"},{"iconClass":"fa-tag","objectID":"3b56dd5b8bf3a348e5856e2f5468e623","title":"Css","type":"tag","url":"/tags/css"},{"iconClass":"fa-tag","objectID":"3f577cb99be4552b5f93e9f67bb4bbce","title":"Emulation","type":"tag","url":"/tags/emulation"},{"iconClass":"fa-tag","objectID":"6d3c377f0c66ea2dc5065ccb9a884d58","title":"Firefox","type":"tag","url":"/tags/firefox"},{"iconClass":"fa-tag","objectID":"44dcf69457fc15c0b678439301ac7058","title":"Font","type":"tag","url":"/tags/font"},{"iconClass":"fa-tag","objectID":"c0fa44cc1e5090f66a1b74b3f5e5e691","title":"Framework","type":"tag","url":"/tags/framework"},{"iconClass":"fa-tag","objectID":"5fbc7ebbae8c3a8789e056db1ebdb6ad","title":"Git","type":"tag","url":"/tags/git"},{"iconClass":"fa-tag","objectID":"e46d699f087c01bc4efdc94b9e5dff1b","title":"Gitignore","type":"tag","url":"/tags/gitignore"},{"iconClass":"fa-tag","objectID":"f88821add0f40470a567fecaca1d6b11","title":"Hack","type":"tag","url":"/tags/hack"},{"iconClass":"fa-tag","objectID":"aae463df5dd553a5098bb56f2cf7175a","title":"Ie","type":"tag","url":"/tags/ie"},{"iconClass":"fa-tag","objectID":"15e6edfa12b677381ce7e9e724d04601","title":"Linux","type":"tag","url":"/tags/linux"},{"iconClass":"fa-tag","objectID":"9f4b8093c53d4b50b1cfb6ca04db2be4","title":"Markdown","type":"tag","url":"/tags/markdown"},{"iconClass":"fa-tag","objectID":"5fb6e45b5ce24354fca66b2827f548a2","title":"Microsoft","type":"tag","url":"/tags/microsoft"},{"iconClass":"fa-tag","objectID":"331bb1ccdcc7dd1b50220e318f34c92a","title":"Mysql","type":"tag","url":"/tags/mysql"},{"iconClass":"fa-tag","objectID":"8ac541a47e70ce8ae1c48a3fd62bf832","title":"Networking","type":"tag","url":"/tags/networking"},{"iconClass":"fa-tag","objectID":"57fb3bef4e1431f9ce0898ae19a13f14","title":"Nginx","type":"tag","url":"/tags/nginx"},{"iconClass":"fa-tag","objectID":"294e831e90838251d50126c93d5c9842","title":"Onedrive","type":"tag","url":"/tags/onedrive"},{"iconClass":"fa-tag","objectID":"0a700efedf7f5b1cc651be1339fc7342","title":"Onedrived","type":"tag","url":"/tags/onedrived"},{"iconClass":"fa-tag","objectID":"23eac3a3f2f4f8751823bf414522b3d3","title":"Outlook","type":"tag","url":"/tags/outlook"},{"iconClass":"fa-tag","objectID":"6270666e9ca90743a31d14fbb659ccf1","title":"Php","type":"tag","url":"/tags/php"},{"iconClass":"fa-tag","objectID":"da8a619ac018916a8e258eeae38884ac","title":"Project","type":"tag","url":"/tags/project"},{"iconClass":"fa-tag","objectID":"a71fff9cdceae6c5f05270844ab11d9e","title":"Purdue","type":"tag","url":"/tags/purdue"},{"iconClass":"fa-tag","objectID":"68749503df24ac5998de9495b2f65281","title":"Python","type":"tag","url":"/tags/python"},{"iconClass":"fa-tag","objectID":"cea2609323942268d9511b7d5a4069b5","title":"Qemu","type":"tag","url":"/tags/qemu"},{"iconClass":"fa-tag","objectID":"6441c13715664fa64513452af6dd089a","title":"Quote","type":"tag","url":"/tags/quote"},{"iconClass":"fa-tag","objectID":"c03f4e851f26378907309cc96240d3b0","title":"Raspberry pi","type":"tag","url":"/tags/raspberry-pi"},{"iconClass":"fa-tag","objectID":"9e156c194addc4a5b9678b4465529c9d","title":"Suricata","type":"tag","url":"/tags/suricata"},{"iconClass":"fa-tag","objectID":"a39bffbec77f50d56daee4fe7f927457","title":"Titillium","type":"tag","url":"/tags/titillium"},{"iconClass":"fa-tag","objectID":"87f605f03b9e62f9858b6e895c343812","title":"Troubleshoot","type":"tag","url":"/tags/troubleshoot"},{"iconClass":"fa-tag","objectID":"51692c2bc8a3b37dc5ef252e4c7cfc6f","title":"Ubuntu","type":"tag","url":"/tags/ubuntu"},{"iconClass":"fa-tag","objectID":"22871f89f3939406ec9bbe6ed955259a","title":"Virtualization","type":"tag","url":"/tags/virtualization"},{"iconClass":"fa-tag","objectID":"fdacda0eb519df99328724f26dc8a4ae","title":"Windows","type":"tag","url":"/tags/windows"},{"author":"xbu","categories":["project","purdue","networking","suricata","benchmark","virtualization"],"content":"Containers like LXC are becoming a popular solution to program isolation. Compared to virtual machines (VM), containers tend to have less resource overhead and higher performance, which makes it interesting to explore how much benefit we can get from deploying virtual network functions (VNF) with containers instead of VMs. Therefore, we conducted an experiment in which we compared performance and resource usage of Suricata, a popular multi-threaded IDS program, in bare metal, Docker container, and virtual machine setups, and in different load levels and resource allocation configurations.\n\nNote: the experiment was conducted during April - May 2016.\nCode repository: GitHub\nThe full text is accessible here.\nUpdate The huge overhead showed in VM is largely due to profiling (which relies heavily on X86 rdtsc instruction) being enabled.\nMethod Use tcpreplay to replay some Pcap traffic files collected from the Internet, and analyze performance of Suricata (running in bare metal, Docker, and VM, respectively) from statistics it reports and resource usage of related processes and resource availability of the entire host.\nWhen comparing Docker container and VM, we will also tune the resource limit and see how Suricata will perform.\nHardware We use four servers (the cluster of which is called \u0026ldquo;cap\u0026rdquo;) of the same hardware configuration. They form two pairs of test setups \u0026ndash; (cap03, cap09) and (cap06, cap07). cap03 and cap06 are hosts to run Suricata, while cap09 and cap07 are hosts to run tcpreplay (which is CPU intensive) and control script. The two hosts of each pair are connected directly by an Ethernet cable.\nAll four machines have the following hardware configuration:\n CPU: Intel Xeon X3430 @ 2.40GHz (Nehalem; EIST/C-states disabled; VT-x on, VT-d on; HT unsupported) RAM: 2 x 2 GB DDR3-1333 RAM HDD: 500GB Seagate 3.5\u0026rdquo; 7200RPM + 2 x 1TB Seagate 3.5\u0026rdquo; 7200RPM Network: 2 x Broadcom 1Gbps NIC. em1 (enp32s0 on cap03/cap06) is used for remote access and management, and em2 (enp34s0 on cap03/cap06) is used to transmit the test traffic.  Software Sender Host (cap07/cap09) Senders run Ubuntu Server 14.04.4 64-bit.\n   Package name Version     gcc 4.8.4   tcpreplay 4.1.1   python3 3.4   python3-spur 0.3.16   python3-psutil 4.1.0    Receiver Host (cap03/cap06) Receivers run Ubuntu Server 15.10 64-bit. The reason is that many packages (particularly QEMU, which dates 8 years ago) on Ubuntu 14.04 are too old; some (libvirt 1.2.2) are even buggy.\n   Package Host Docker VM     Docker 1.11.0 - -   libvirt 1.2.16 - -   gcc 5.2.1 5.2.1 5.2.1   Suricata 3.0.1 3.0.1 3.0.1   Emerging Rules 20160414 20160414 20160414   python3 3.4 - 3.4   python3-spur 0.3.16 - -   python3-psutil 4.1.0 - 4.1.0    The docker image and VM try to resemble software of host system, running Ubuntu Server 15.10 64-bit and making sure all critical packages are of the same version as the host.\nSide notes  To use streamlined test script, host user and sender must be able to run sudo without password prompt (sudo visudo and add username ALL=(ALL) NOPASSWD: ALL). Use SSH authorized_keys to facilitate SSH login.  Suricata Suricata loads the free version of Emerging Rules as of 2016-04-14.\nUnless otherwise noted, Suricata uses default configuration generated when installed to the system.\nSuricata 3.0.1, released on April 4, 2016, fixed many memory leak bugs and improved stability. This can be confirmed by our previous testing of 3.0 version inside VM setup, which resulted in memory thrashing and can barely be tested in any load above moderate.\nTrace files We use the following flows available from the Internet:\n Sample flows provided by TCPreplay \u0026ndash; bigFlows.pcap (359,457 KB), smallFlows.pcap (9,224 KB). Sample traces collected by WireShark Publicly available PCAP files ISTS\u0026rsquo;12 trace files \u0026ndash; randomly picked snort.log.1425823194 (155,823 KB).  bigFlows.pcap According to TCPreplay website, bigFlows.pcap has the following characteristics:\n This is a capture of real network traffic on a busy private network\u0026rsquo;s access point to the Internet. The capture is much larger and has a smaller average packet size than the previous capture. It also has many more flows and different applications. If the large size of this file isn\u0026rsquo;t a problem, you may want to select it for your tests.\n Size: 368 MB Packets: 791615 Flows: 40686 Average packet size: 449 bytes Duration: 5 minutes Number Applications: 132   From the log of Suricata we can confirm that the traffic consists of numerous procotols on various ISO/OSI layers.\nThe peak throughput of the trace is approximately 2.13 MBps (diagram will given later), so our Ethernet link will support less than 50 concurrent TCPreplay processes. However, CPU of the sender host saturates at 4 concurrent TCPreplay processes; it takes longer for all TCPreplay processes to finish replaying above that concurrency level (e.g., peak throughput less than doubles at concurrency level 16 compared to concurrency level 4, because at level 16 it can take 3X more time to finish). For this reason, test results above concurrency level 4 are not comparable to those equal to or below that level. Results not in the same concurrency level above 4 are not cross-comparable either.\nsnort.log.1425823194 This trace file requires much higher processing speed than bigFlows.pcap.\n  Rated: 6928500.0 Bps, 55.42 Mbps, 6264.04 pps Flows: 1833 flows, 80.74 fps, 140196 flow packets, 2006 non-flow Duration: ~22 seconds   Performance Analysis We analyze the performance of Suricata by comparing speed of packets / bytes captured, speed of packets / bytes decoded, and speed of alerts triggered for different setups when playing the same trace with the same number of parallel workers. Theoretically the speed of traffic sent is the same, so the difference of those speeds result from the receiver setup.\nSuricata generates stats every 8 seconds (default value).\nResource Monitoring We use a Python script based on Python3 psutil package. It periodically polls the system-wide CPU, memory, and Disk I/O usage, and optionally the traffic sent / received on specified NIC, and sum of resource usage of a subset of processes (e.g., docker processes and their children processes) and outputs the information to a CSV file. We compared the numbers with popular system monitor programs like top, htop, atop (buggy, discussed later) and can confirm that the numbers are correct and the periods between polls are (almost perfectly) constant.\nResource monitor polls stats every 4 seconds.\nThe source code of resource monitor is hosted in tester_script/ directory.\nWhy not use top or atop directly?\n Because top and atop polls more numbers than needed, they incur much higher overhead on the receiver system. Output is not friendly for post-processing, even after CSV-fied. Lines of top do not contain timestamps; because we start monitors before Suricata, we cannot ask monitors to poll information of Suricata process (its PID not known beforehand). atop behaves wrong on our system. When running VM setup, atop reports 50% of CPU usage each core while in fact they are all 100% (confirmed by htop and top). Because atop and top (which needs to monitor several processes like two docker processes and one Suricata-Main process) are separate processes, their output seldom hits the same timestamp, and thus the sum of the reported numbers is not accurate.  By contrast, our monitor script prints neatly for each polling timestamp all the system-wide resource availability and sum of resource usage of the processes we are interested in one CSV line. This makes post-processing easy as well.\nWhy examine system-wide resource usage?\nBecause the sum of resource usage of processes that are directly related may not be comprehensive. For example, the RAM usage of mirroring traffic to macvtap is not in any suricata, docker, or qemu processes.\nSystem-wide numbers could over-count, but as we are comparing the difference, which results from different setups of Suricata, the over-counted part doesn\u0026rsquo;t matter.\nTest Setups Bare metal In bare metal setting, Suricata will run directly on top of hardware and inspect the NIC that the test traffic enters.\nDocker In this Docker setting, the container is configured so that the network interfaces of the host is exposed to the container, enabling Suricata to inspect the same NIC interface as in bare metal setting.\nThe CPU and RAM limitations can be passed as parameters of the test script. By default, it allows the container to access all 4 cores and has a RAM limit of 2GB (1536m and 1g are also tested).\nDocker + macvtap In Docker-vtap setting, the difference from Docker setup is that we create a macvtap of model \u0026ldquo;virtio\u0026rdquo; and mode \u0026ldquo;passthrough\u0026rdquo; to mirror the traffic arriving at host\u0026rsquo;s enp34s0 NIC, and let Suricata in Docker inspect the traffic on the macvtap device. This is an \u0026ldquo;intermediate\u0026rdquo; setup between Docker setup and VM setup, because the cost of running macvtap is unavoidable in VM setup.\nIn the text that follows, I will use \u0026ldquo;DockerV\u0026rdquo; to refer to this setup.\nVirtual machine The virtual machine hardware is configurable. Default configurations are available in XML format in config/. Different CPU and RAM configuration may be passed as parameters of the test script. By default, it has 4 vCPUs each of which has access to all 4 cores of the host CPU. Capacities of vCPU are copied from host CPU (\u0026ldquo;host-model\u0026rdquo;). RAM is set to 2 GB. In terms of NIC, We create a macvtap device (macvtap0) of model \u0026ldquo;virtio\u0026rdquo; and mode \u0026ldquo;passthrough\u0026rdquo; to copy the test traffic arriving at host\u0026rsquo;s enp34s0 to VM\u0026rsquo;s eth1. Another NIC, eth0, is added for communications between host and the VM.\nThe exact hardware configuration will be mentioned when comparing results.\nThe virtual disk has size of 64 GiB, large enough to hold logs of GB magnitude.\nTest cases We have the following tests:\n   Setup Trace file Para. TCPreplays Use VTAP? Memory* CPU Swappiness Other Args Sample Size     Bare metal bigFlows.pcap 1 No 4 GB 4 5 - 40   Docker bigFlows.pcap 1 No 2 GB 4 5 - 40   Docker + vtap bigFlows.pcap 1 Yes 2 GB 4 5 - 40   VM bigFlows.pcap 1 Yes 2 GB 4 5 vCPUs=4 40   Bare metal bigFlows.pcap 2 No 4 GB 4 5 - 40   Docker bigFlows.pcap 2 No 2 GB 4 5 - 40   Docker + vtap bigFlows.pcap 2 Yes 2 GB 4 5 - 40   VM bigFlows.pcap 2 Yes 2 GB 4 5 vCPUs=4 40   Bare metal bigFlows.pcap 3 No 4 GB 4 5 - 40   Docker bigFlows.pcap 3 No 2 GB 4 5 - 40   Docker + vtap bigFlows.pcap 3 Yes 2 GB 4 5 - 40   VM bigFlows.pcap 3 Yes 2 GB 4 5 vCPUs=4 40   Bare metal bigFlows.pcap 4 No 4 GB 4 5 - 40   Docker bigFlows.pcap 4 No 2 GB 4 5 - 40   Docker + vtap bigFlows.pcap 4 Yes 2 GB 4 5 - 40   VM bigFlows.pcap 4 Yes 2 GB 4 5 vCPUs=4 40   Bare metal bigFlows.pcap 8 No 4 GB 4 5 - 30   Docker bigFlows.pcap 8 No 2 GB 4 5 - 25   Docker + vtap bigFlows.pcap 8 Yes 2 GB 4 5 - 25   VM bigFlows.pcap 8 Yes 2 GB 4 5 vCPUs=4 30   Bare metal bigFlows.pcap 16 No 4 GB 4 5 - 10   Docker bigFlows.pcap 16 No 2 GB 4 5 - 10   Docker + vtap bigFlows.pcap 16 Yes 2 GB 4 5 - 10   VM bigFlows.pcap 16 Yes 2 GB 4 5 vCPUs=4 10   Docker bigFlows.pcap 4 No 1024 MB 4 5 - 30   Docker + vtap bigFlows.pcap 4 Yes 1024 MB 4 5 - 30   VM bigFlows.pcap 4 Yes 1024 MB 4 5 vCPUs=4 40   Docker bigFlows.pcap 4 No 512 MB 4 5 - 10   Docker + vtap bigFlows.pcap 4 Yes 512 MB 4 5 - 10   VM bigFlows.pcap 4 Yes 512 MB 4 5 vCPUs=4 30   Bare metal snort.log.1425823194 1 No 4 GB 4 5 stat=1s 30   Docker snort.log.1425823194 1 No 2 GB 4 5 stat=1s 30   Docker + vtap snort.log.1425823194 1 Yes 2 GB 4 5 stat=1s 30   VM snort.log.1425823194 1 Yes 2 GB 4 5 stat=1s, vCPUs=4 30   Bare metal snort.log.1425823194 2 No 4 GB 4 5 stat=1s 30   Docker snort.log.1425823194 2 No 2 GB 4 5 stat=1s 30   Docker + vtap snort.log.1425823194 2 Yes 2 GB 4 5 stat=1s 30   VM snort.log.1425823194 2 Yes 2 GB 4 5 stat=1s, vCPUs=4 30   Bare metal snort.log.1425823194 4 No 4 GB 4 5 stat=1s 30   Docker snort.log.1425823194 4 No 2 GB 4 5 stat=1s 30   Docker + vtap snort.log.1425823194 4 Yes 2 GB 4 5 stat=1s 30   VM snort.log.1425823194 4 Yes 2 GB 4 5 stat=1s, vCPUs=4 30    Notes\n From the perspective of physical host, neither Docker nor QEMU strictly enforces this memory limit. The actual memory usage can go slightly higher.\n For some test setups, the variation is so low that it\u0026rsquo;s not worth repeating many times. For some tests the variation is high and more rounds are run to get satisfiably large sample. Some tests were run significantly more times because the test scripts were copied and pasted.\n The number of CPU cores is not manipulated because we can gain insight from different load levels. Actually CPU is the bottleneck for most test setups.\n  We ran each test multiple times to generate a number of samples (as shown the sample size column). Before running every test, the receiver host is rebooted to make sure system state is restored back to original. After all samples are generated, we use the median of all samples at each checkpoint to obtain an average result of the test. We then compare the average results of tests.\nThe script to parse raw CSV / Suricata eve.json files is hosted in dataparser/ directory.\nNote: after a test is run, all generated log files will be transferred to server cap08 using rsync. There are occasional glitches on public network which could cause failure (connection timeout) of transmission. This is the reason why the sample size of some tests are slightly smaller. I don\u0026rsquo;t know why the clusters become inaccessible during those minutes.\nResult We analyze the results of the two trace files, respectively.\nbigFlows.pcap Throughput The following is the recorded throughput of trace bigFlows.pcap when played by one TCPreplay process. When there are two, three, or four TCPreplay processes, the throughput is simply multiplied because the sender host is not saturated in terms of CPU, memory, or NIC throughput. This can be confirmed by the system stat log of sender host.\nIn the following sections, I\u0026rsquo;ll use \u0026ldquo;load\u0026rdquo; to mean a unit of TCPreplay process. For example, \u0026ldquo;2X load\u0026rdquo; means using two concurrent TCPreplay processes.\nComparing CPU Usage of Four Setups It takes about 8 seconds for Suricata to initialize for all four setups. After Suricata loads, the sender will start replaying the trace.\nAt 1X load, we see that Docker and DockerV setups use almost the same amount of CPU share as that of bare metal setup, fluctuating near 25%, whereas the VM raises the host CPU usage to a range between 200% and 350%. The CPU usage of VM setup fluctuates greatly but is highly correspondent to the trace throughput. Note that when the VM runs without Suricata, the host CPU usage is about 2% to 5%.\nAt 2X load level, we see that the CPU usage of bare metal, Docker, and DockerV setups doubles but still close to each other, and the VM setup has host CPU saturated.\n3X and 4X load levels reveal similar result \u0026ndash; CPU usage tripled and quadrupled, respectively, compared to 1X load level, and VM setup consumed all host CPU resource.\nComparing CPU Usage of Bare Metal and Docker Setups Here is a diagram that puts the CPU usage of all setups except for VM and at ll load levels:\nWe see that Docker layer imposes trivial (with respect to overall CPU usage) overhead to host CPU when Suricata inspects the trace traffic at all four load levels.\nBut what\u0026rsquo;s the overhead of macvtap traffic mirroring?\nCPU Overhead of Docker and Macvtap By comparing the CPU usage of Bare metal, Docker, and DockerV setups, we can gain insight on how much overhead Docker and macvtap introduces, respectively:\nWhile the CPU usage overhead of Docker is trivial at 4X load, there is a roughly 0% to 5% increase in CPU usage with macvtap, depending on traffic throughput. Note that we found macvtap of mode \u0026ldquo;passthrough\u0026rdquo; (requiring VT-d and SR-IOV) and model \u0026ldquo;virtio\u0026rdquo; the approach that incurs the least overhead compared to other ways of redirecting traffic including bridging, Virtual Ethernet Port Aggregator (VEPA), etc. With other approaches of redirecting traffic, the overhead can go higher.\nBy making this comparison we see that\n By exposing the host NIC directly to Docker container, the overhead of mirroring traffic can be saved. The high CPU usage of VM setup is not caused by macvtap traffic redirection; however, the CPU resource needed to redirect traffic it not negligible.  Comparing Memory Usage of Four Setups The result of memory usage is so simple that they can be put in one diagram:\nWe see that increasing the load level barely increases the host memory usage on bare metal, Docker, and Docker with vtap setups. However, increasing load level dramatically increases the host memory usage on VM setup.\nNote that even though after 150 seconds the memory usage of 2X, 3X, 4X load levels is about the same for VM setups, for those load levels, it\u0026rsquo;s the host CPU that is a bottleneck. This prevents Suricata from increasing speed and taking more memory, and also explains why the memory usage there slightly decreases as load increases \u0026ndash; CPU is saturated and the system needs more CPU time to handle the network traffic, making Suricata run with even less resource. It\u0026rsquo;s still noteworthy that for VM setup when CPU is not a bottleneck, the host observes an up to 15% memory usage increase. I therefore conjecture that if CPU were not a bottleneck, the memory usage will go spectacularly higher.\nIn terms of overhead, while the bare metal consumes about 10% of CPU usage, Docker setups impose trivial memory head, whereas the VM setup can eat three times as much, resulting in a up to 250% overhead when busy and 300% when idle.\nMemory Usage inside KVM We also investigate how much memory is used inside VM and on host. From the graph below we see that the VM has not saturated its 2GB memory limit. We therefore understand that for our test setups memory is not a bottleneck.\nComparing Performance of Suricata in Four Setups Suricata exports performance metric in intervals of, by default, 8 seconds, to log files. We examine the log file and compare the following metrics:\n _capture.kernelpackets: The accumulative number of packets Suricata has captured. _capture.kerneldrops: The accumulative number of packets Suricata has dropped. decoder.pkts: The accumulative number of packets Suricata has decoded. decoder.bytes: The accumulative amount of data, in Bytes, Suricata has decoded. We post processed the data to use unit of KiB rather than B.  We do not examine the number of alerts triggered because it\u0026rsquo;s highly affected by packet dropping.\nPacket Capturing We see that in all four load levels we use, packet capturing is about the same for all four setups. However, the VM setup tends to receive less packets in the end. Usually TCPreplay ends at second 312 and we send SIGTERM signal to Suricata 30 seconds after and wait for it to exit gracefully. It\u0026rsquo;s very likely that for VM setup it still has packets yet to capture when exiting, resulting in the discrepancy we see here.\nPacket Dropping Packet dropping is a sign that Suricata can\u0026rsquo;t process the workload given the resource it can utilize. Only VM setup observes packet drop starting from 2X load, and almost all increased load beyond 2X is dropped.\nData Decoding Because the data cannot fit well in one graph, we first compare Docker setups with bare metal, and then VM setup with baremetal.\nWe first compare Docker and DockerV setups with bare metal, and see that there is no nontrivial difference between the three. In this case, there is no need to compare the number of bytes decoded because they will be on par with each other.\nWe then compare VM setup with bare metal.\nWe see that while the decoding speed is comparable at 1X load, the decoding speed of VM Suricata is significantly lower as load increases from 2X to 4X, and there is no difference in decoding between 3X load and 4X load, which indicates that Suricata is saturated.\nIf we switch unit to KBytes, we see that as load increases, Suricata in VM runs slower and slower.\nWhen Memory Is Also a Bottleneck In the previous tests, we set memory limit of 2GB which turns out sufficient for all setups and all four load levels. In this part we change memory limit to 512MB and see how resource usage and performance would change. From our previous tests we see that even 512MB is sufficient for 1X load on VM yet CPU becomes bottleneck of VM since 2X load. While we could tweak the parameters to isolate the CPU bottleneck, it\u0026rsquo;s also reasonable to change the memory limit and observe the difference. Note that we did test with 1GB memory limit, but it turns out no difference from 2GB limit since VM\u0026rsquo;s CPU bottleneck prevented VM from consuming more memory.\nTherefore we compare the following two setups: DockerV versus VM under 512MB memory limit and 4X load. We choose those two setups so that the overhead of macvtap appears on both sides. For convenience we include their 2GB counterparts in the graphs.\nHost CPU Usage We see that 512MB has no effect on DockerV setup, but the CPU usage starts to decrease for 512MB VM since around 150 second. As we will see in a later graph, VM memory saturates there and thrashing occurs.\nHost Memory Usage There is not much to say about host memory usage. There is no difference between 2GB limit and 512MB limit in DockerV setup, while the VM memory hits its limit and cannot increase further. The memory increase after the point of thrashing is largely due to host caching the disk swap I/O of VM.\nMemory Usage in VM Memory usage in VM confirms that thrashing starts after approx. 150 seconds. We will inspect the memory usage drop near 328 second with behavior of Suricata.\nPerformance of Suricata We see that Suricata in DockerV setup shows no difference in performance given the two memory limits as the lines for their packet captured match well, and neither drop any packets. KVM with 2GB memory limit matches the DockerV packet captured line well until near the end; its lack of CPU power makes it impossible for Suricata to finish with all packets within the given time frame.\nWhat\u0026rsquo;s worth noting is that the graph seems to indicate that 512MB KVM Suricata captures more packets than other scenarios. However, this is not the case. Memory thrashing inside VM drifts Suricata\u0026rsquo;s logging intervals (in unit of seconds), and when we put all series into one X-axis the drift is assumed non-existent even though it gets increasingly severe as time goes by. This can be verified by comparing the raw statistics of NIC traffic on host and inside VM manually.\nWe see that Suricata inside 512MB VM is struggling to make slow progress, while Suricata in 512MB DockerV works just fine. Note that the slight drop of the line for 512MB KVM near 360 second is caused by the fact that we take medians of samples.\nIncreasing the Load Level From result of other test configurations, we see that Docker setup is on a par with bare metal in terms of both resource usage and performance, up to 32X load level, beyond which we did not test since the sender host would be overly saturated.\nWhy is Suricata in VM that slow? To further investigate how Suricata consumes way more CPU in VM than in bare metal, we use oprofile to profile the execution of Suricata with 4X load in bare metal and in VM, respectively. The result is hosted in oprofile_data/ directory.\nThe function calls that consume most of (aggregated) CPU time on host execution are:\nsamples % linenr info app name symbol name 3079940 48.7275 util-cpu.c:190 suricata UtilCpuGetTicks 889800 14.0775 util-mpm-ac.c:1307 suricata SCACSearch 573918 9.0799 detect.c:1237 suricata SigMatchSignatures  While the function calls that consume most of CPU time on VM execution are:\nsamples % linenr info app name symbol name 3876496 77.4428 util-cpu.c:190 suricata UtilCpuGetTicks 378915 7.5698 detect.c:1237 suricata SigMatchSignatures 144521 2.8872 util-mpm-ac.c:1307 suricata SCACSearch 78725 1.5727 util-profiling.c:994 suricata SCProfileRuleStart  We see that the function UtilCpuGetTicks() consumes about 48.73% of CPU time of Suricata process on bare metal whereas it consumes 77.44% in KVM. With detailed report from oprofile we see that it is the seven processing threads that rely heavily on this function, whereas the four management threads do not.\nWe then wonder which instruction in this function takes most time. Assembly wise, on host\n0000000000736ca0 \u0026lt;UtilCpuGetTicks\u0026gt;: /* UtilCpuGetTicks total: 3079940 48.7275 */ 19614 0.3103 : 736ca0: push %rbx 1345 0.0213 : 736ca1: xor %eax,%eax : 736ca3: cpuid 1281367 20.2724 : 736ca5: rdtsc 391861 6.1996 : 736ca7: mov %edx,%edi 20 3.2e-04 : 736ca9: mov %eax,%esi : 736cab: xor %eax,%eax : 736cad: cpuid 1300635 20.5772 : 736caf: mov %rdi,%rax 33929 0.5368 : 736cb2: pop %rbx 51165 0.8095 : 736cb3: shl $0x20,%rax 4 6.3e-05 : 736cb7: or %rsi,%rax : 736cba: retq : 736cbb: nopl 0x0(%rax,%rax,1)  while in KVM\n0000000000736ca0 \u0026lt;UtilCpuGetTicks\u0026gt;: /* UtilCpuGetTicks total: 3876496 77.4428 */ 3201 0.0639 : 736ca0: push %rbx 421 0.0084 : 736ca1: xor %eax,%eax 1 2.0e-05 : 736ca3: cpuid 1760507 35.1706 : 736ca5: rdtsc 159997 3.1963 : 736ca7: mov %edx,%edi 5 1.0e-04 : 736ca9: mov %eax,%esi : 736cab: xor %eax,%eax 2477 0.0495 : 736cad: cpuid 1783625 35.6324 : 736caf: mov %rdi,%rax 110918 2.2159 : 736cb2: pop %rbx 55341 1.1056 : 736cb3: shl $0x20,%rax 3 6.0e-05 : 736cb7: or %rsi,%rax : 736cba: retq : 736cbb: nopl 0x0(%rax,%rax,1)  We find that it takes significantly more (aggregated) time to read x86 Timestamp Counter (TSC) register as the instruction rdtsc shows, and to move register value from %rdi to %rax.\nUnfortunately we fail to obtain a callgraph from oprofile which could let us know the reason why it spends more time on those instructions \u0026ndash; is it simply because those instructions run slowly in VM? Or is it because this function is triggered more frequently?\nTo investigate this, we copy the source code of UtilCpuGetTicks into separate C file test_rtdsc.c, and write a main function that calls this function 10^8 times. We run this program in both bare metal and VM, measuring how much time it takes to finish with time command, and the distribution of time onto the instructions with oprofile. The raw result is saved in test_rdtsc/ directory.\nWe find that it takes only 6.6 seconds (43.35% attributable to rdtsc) in bare metal, but 126.09 seconds (47.90% attributable to rdtsc) inside VM. We also note that the instruction to update the loop counter, which is the first instruction after cpuid, also takes significant amount of time (44.34% in bare metal; 47.44% in VM).\nAccording to Table 21-6, Intel Manual Volume 3B, pp.21-13, the instruction rdtsc could trigger a VM exit, making the instruction expensive in VM environment.\nThe instruction cpuid is often paired with rdtsc to prevent rdtsc from being executed out-of-order:\n In order to keep the RDTSC instruction from being performed out-of-order, a serializing instruction is required. A serializing instruction will force every preceding instruction in the code to complete before allowing the program to continue. One such instruction is the CPUID instruction, which is normally used to identify the processor on which the program is being run. For the purposes of this paper, the CPUID instruction will only be used to force the in-order execution of the RDTSC instruction.\n \u0026ndash; Coorporation, I. (1997). Using the RDTSC Instruction for Performance Monitoring. Techn. Ber., tech. rep., Intel Coorporation, 22.\nWith a tool provided in QEMU repository written by Avi Kivity avi@redhat.com, we can check the \u0026ldquo;Primary Processor-Based VM-Execution Controls\u0026rdquo; of our test CPU:\nsudo ./vmxcap.py Basic VMX Information Revision 14 VMCS size 1024 VMCS restricted to 32 bit addresses no Dual-monitor support yes VMCS memory type 6 INS/OUTS instruction information yes IA32_VMX_TRUE_*_CTLS support yes pin-based controls External interrupt exiting yes NMI exiting yes Virtual NMIs yes Activate VMX-preemption timer yes Process posted interrupts no primary processor-based controls Interrupt window exiting yes Use TSC offsetting yes HLT exiting yes INVLPG exiting yes MWAIT exiting yes RDPMC exiting yes RDTSC exiting yes CR3-load exiting default CR3-store exiting default CR8-load exiting yes CR8-store exiting yes Use TPR shadow yes NMI-window exiting yes MOV-DR exiting yes Unconditional I/O exiting yes Use I/O bitmaps yes Monitor trap flag yes Use MSR bitmaps yes MONITOR exiting yes PAUSE exiting yes Activate secondary control yes secondary processor-based controls Virtualize APIC accesses yes Enable EPT yes Descriptor-table exiting yes Enable RDTSCP yes Virtualize x2APIC mode yes Enable VPID yes WBINVD exiting yes Unrestricted guest no APIC register emulation no Virtual interrupt delivery no PAUSE-loop exiting no RDRAND exiting no Enable INVPCID no Enable VM functions no VMCS shadowing no RDSEED exiting no EPT-violation #VE no Enable XSAVES/XRSTORS no VM-Exit controls Save debug controls default Host address-space size yes Load IA32_PERF_GLOBAL_CTRL yes Acknowledge interrupt on exit yes Save IA32_PAT yes Load IA32_PAT yes Save IA32_EFER yes Load IA32_EFER yes Save VMX-preemption timer value yes VM-Entry controls Load debug controls default IA-32e mode guest yes Entry to SMM yes Deactivate dual-monitor treatment yes Load IA32_PERF_GLOBAL_CTRL yes Load IA32_PAT yes Load IA32_EFER yes Miscellaneous data VMX-preemption timer scale (log2) 5 Store EFER.LMA into IA-32e mode guest control no HLT activity state yes Shutdown activity state yes Wait-for-SIPI activity state yes IA32_SMBASE support no Number of CR3-target values 4 MSR-load/store count recommendation 0 IA32_SMM_MONITOR_CTL[2] can be set to 1 no VMWRITE to VM-exit information fields no MSEG revision identifier 0 VPID and EPT capabilities Execute-only EPT translations yes Page-walk length 4 yes Paging-structure memory type UC yes Paging-structure memory type WB yes 2MB EPT pages yes 1GB EPT pages no INVEPT supported yes EPT accessed and dirty flags no Single-context INVEPT yes All-context INVEPT yes INVVPID supported yes Individual-address INVVPID yes Single-context INVVPID yes All-context INVVPID yes Single-context-retaining-globals INVVPID yes VM Functions EPTP Switching no  So for our test environment rdtsc IS yielding VM exiting, and combined with cpuid, giving huge performance penalty to Suricata running inside a virtual machine.\nSummary We see that Docker incurs trivial resource overhead compared to bare metal, while KVM\u0026rsquo;s overhead is order of magnitude more than what Suricata itself uses. In terms of performance, while Docker imposes negligible, if any, penalty, KVM makes it much less efficient to run Suricata\u0026rsquo;s instructions and makes CPU a bottleneck at relatively low load levels.\nsnort.log.1425823194 Throughput The trace file snort.log.1425823194 sends high volume of data in short period of time (about 22 seconds). Data is collected with granularity of 1 second.\nPerformance of Suricata The final result of the tests is as follows.\n   Setup Load Time Dropped.Pkts Decoded.Pkts Decoded.B     Bare Metal 1X 29 s 0 142202 157287081   Docker 1X 28 s 0 142202 157287081   DockerV 1X 26 s 0 142203 157287081   KVM 1X 18 s 18788 71412 79238466   Bare Metal 2X 28 s 0 284404 314574162   Docker 2X 27 s 0 284404 314574162   DockerV 2X 26 s 0 284405 314574232   KVM 2X 18 s 98456 81927 90416861   Bare Metal 4X 29 s 67126 500749 552477875   Docker 4X 27 s 67064 500793 553071996   DockerV 4X 27 s 81282 487527 537692948   KVM 4X 18 s 277529 81260 89281369    Note: Time column is the amount of time it takes to reach stable value. Because we take medians of all samples to form a representation, at least half samples complete by that time.\nWe see that in terms of performance Docker setup is on a par with bare metal even when CPU is stressed at 4X load. Macvtap consumes CPU, resulting in DockerV setup dropping more packets than Docker setup at 4X load, but it is still in the same magnitude as Docker and bare metal setups.\nThe result of VM setup is noteworthy. Not only it drops significantly more packets, but a nontrivial portion of packets (358789 captured / 568808 total) isn\u0026rsquo;t even captured. In the following section, we will dive deeper into what happens to VM setup at 4X load.\nInvestigating the VM Issue The following graph puts the cumulative number of packets sent (light blue line), cumulative number of packets received on the VM (orange line), cumulative number of packets captured (gray bar) / dropped (yellow bar) / decoded (dark blue bar) by Suricata, host CPU usage (green line, percentage), and VM memory usage (dark blue line, percentage) together:\nNote that because we are taking medians, cumulative number of packets sent is not necessarily equal to cumulative number of packets received. I manually inspected several instances and for those instances they are indeed equal.\nWe see from the graph that Suricata packet capturing thread(s) never manages to process packets that come every single second. Most new packets are dropped and few are decoded. CPU usage reaches ceiling near second 10 and remains high for a few seconds. My guess is that because Suricata can\u0026rsquo;t read packets fast enough, the kernel buffer to hold packets becomes full and new packets are simply dropped. When Suricata catches up it no longer finds more packets to process.\nAfter further checking, it turns out the the performance degradation is largely due to the fact that X86 rdtsc instruction cannot run efficiently in VM environment. It\u0026rsquo;s mostly used to get precise timestamps for profiling purposes. Turning down rate of profiling could mitigate the issue, but cannot solve it.\nConclusion We see that container solutions like Docker are way more suitable than virtual machines for light-weight programs like Suricata in that (1) less resource is needed, and (2) the high cost of VM exiting triggered by some instructions can be saved.\nFurther: Experiment with Snort We applied the same experiment to Snort. While the result of Snort is not as overwhelming as that we see on Suricata, performance penalty and resource overhead (VM setup eats 60% more CPU and 100% more RAM compared to Docker) are still significant. The data is also available on the GitHub repository.\n","iconClass":"fa-pencil","objectID":"333799ad40ee5a691a5eda631bd3f288","tags":["project","purdue","networking","suricata","benchmark","virtualization"],"title":"Benchmarking Suricata in Different Isolation Systems Using TCPreplay","type":"article","url":"/article/benchmarking-suricata-in-different-isolation-systems-using-tcpreplay/"},{"author":null,"categories":["font","hack"],"content":"Licensed under CC 4.0, Hack is \u0026ldquo;hand groomed and optically balanced to be your go-to code face\u0026rdquo;.\n","iconClass":"fa-link","objectID":"7e1bbf6fb15697b611fff9fb0d97ee21","tags":["font","hack"],"title":"Hack Font","type":"link","url":"/link/hack-font/"},{"author":"Andy Grove","categories":["quote"],"content":"Only the Paranoid Survive.\n","iconClass":"fa-quote-right","objectID":"992be7eb49248c7e02c6521a9ada58e0","tags":["quote"],"title":"Only the Paranoid Survive","type":"quote","url":"/quote/andy-grove-paranoid/"},{"author":"xbu","categories":["onedrived","project","microsoft","onedrive","linux","python"],"content":"onedrived is a client program for Microsoft OneDrive on Linux platform. It enables you to sync local directories with remote OneDrive repositories (a.k.a., \u0026ldquo;Drive\u0026rdquo;) of one or more OneDrive Personal account (OneDrive for Business accounts are not yet supported).\nThe program is written in Python3, and uses official OneDrive Python SDK to communicate with OneDrive server, Keyring to securely store account credentials, and Linux inotify API to monitor file system changes.\n\nLatest development repo (not well documented yet):\nhttps://github.com/xybu/onedrived-dev\nOld version that uses Live API:\nhttps://github.com/xybu/onedrive-d-old\n","iconClass":"fa-pencil","objectID":"13cb8117119fb648a015d6216f0345ee","tags":["onedrived","project","microsoft","onedrive","linux","python"],"title":"onedrived - Microsoft OneDrive client for Linux","type":"article","url":"/article/onedrived/"},{"author":"xbu","categories":["purdue","git","python"],"content":" Planned in December 2014 and first released in January 2015, gitlab-ag is a project that aims to enhance GitLab, an open-source GitHub-like system, for educational use. The primary goal is to facilitate batch operations on GitLab and integrate automated grading mechanism, thereby replacing the AutoGrader system used in the past. It runs as a standalone website that manipulates GitLab API.\n GitHub Repository: https://github.com/xybu/gitlab-ag\nDocumentation: https://github.com/xybu/gitlab-ag/blob/master/README.md\nLicense: GPLv2\n Features  Import / delete users in batch: import students (GitLab users) from CSV when a new semester starts, and delete all users after semester ends. Create / clone new projects in batch: create new projects of same parameters for (any set of) users, optionally cloning from an existing git repository. Backup at push: so a designated directory will always have the latest copy of monitored projects in GitLab. System event logging and notification: notify instructors if a GitLab system event is emitted. Automated grading: grading the submission after student pushes code to GitLab.  gitlab-ag is built on top of PHP 5.5 with no framework involved. Some auto-grading delegates are written in Python 3k.\nGallery Installation page of gitlab-ag. Import users from CSV content to GitLab Delete users by pattern Add new repository (clone skeleton code repo) for students Why play Git? Based on my observations as a teaching assistant for Purdue CS240 course, using Git to manage student submissions makes it much easier to track their progress and detect cheating. By asking students to continuously git commit their progress on assignments and counting this progress as part of the grade, students have less incentive to risking their grade copying the source code of others. For instructors, analyzing cheating cases becomes much easier thanks to the commit log. The professor and I agreed that both students and instructors would be better off with full experience of Git. So we picked GitLab as the base, and developed gitlab-ag to add extra features we want.\nWhy autograding? With standardized environment, streamlined and sandboxed execution of untrusted code (sorry to say this, but we as instructors cannot trust any student program unless we have read its source code carefully), and automatic generation and notification of grades, grades become less biased. Instructors have more time to help students, and students can know their grade shortly after their submission is graded.\nAutograding is a black-box test procedure, no matter how much code to check student code (e.g., check what functions student program calls, check if the student program uses libraries that arenΓÇÖt allowed, etc.) is written. To mitigate the drawbacks of black-box testing, we also inspect student code for some cases.\n┬áImprovements from AutoGrader There are two noticeable changes from the last update of AutoGrader project:\n The API is simplified so that the test runner can be written in any language besides Python. The output format is up to the test runner as long as the autograder-readable key tag is provided.\n The whole test runs inside Docker container; the whole grading session is virtualized, not just one command. The old isolation tool based on User-mode Linux (UML) is now abandoned.\n  ","iconClass":"fa-pencil","objectID":"03697adbada0d33dda573b541d15c83f","tags":["purdue","git","python"],"title":"gitlab-ag - Combining Git and Autograding","type":"article","url":"/article/gitlab-ag/"},{"author":"xbu","categories":["microsoft","project","csharp","app"],"content":" Grab the pulse of your favorite stocks!\nStockPulse is an unofficial app for StockTwits (https://stocktwits.com), \u0026ldquo;a financial communications platform for the investing community\u0026rdquo;. With StockPulse you can easily manage portfolios (watchlists), follow trending stocks and users, read streams and post messages on your StockTwits account on your Windows Phone 8 device.\nThe app is free and available at Windows Phone Store.\n\nTutorial Hints in general\n Navigating too fast may result in internet failure because StockTwits API has rate limit.  Hints for recent list\n Recent list is a StockPulse-only feature. It contains the stocks you viewed before in case you want to view them again. It could go above 30 stocks if you visit that many stocks, but if you restart the app, it will delete the least recent ones.  Hints for trending list\n Trending list is a collection of trending symbols on StockTwits. While on StockTwits.com it is updated fast, StockPulse does not automatically refresh the list because of rate limit. You may want to click the Refresh icon on bottom app bar to have it refreshed.  Hints for account panel\n Some items are linked to StockTwits.com website because the API we have does not have the permission to modify it.  Hints for user profile page\n Swipe to \u0026ldquo;messages\u0026rdquo; pivot and the user \u0026ldquo;name card\u0026rdquo; will collapse :) I wish this feature makes reading more comfortable.\n \u0026ldquo;Block this user\u0026rdquo; option is in the bottom app bar. Expand the menu and you can see it.\n  Hints for reading messages\n Hit the user name, user handle, or user avatar will navigate you to the user profile page.\n Hit the \u0026ldquo;like\u0026rdquo; button to \u0026ldquo;like\u0026rdquo; the message. If you have liked the message, the icon will be a check mark. Hit the check mark and the message is unliked.\n \u0026ldquo;Pencil\u0026rdquo; icon means there is no comment / follow-up about the message. Click it to compose its first reply.\n If the message has got replied, \u0026ldquo;comments\u0026rdquo; icon will show up instead of \u0026ldquo;pencil\u0026rdquo;, followed by a number indicating the number of comments. Hit it to navigate to the conversation page, where you can reply any message in the discussion.\n A chart thumbnail will show up if there is chart attached to the message. Click it to see the full-sized chart, where you can also save it to your phoneΓÇÖs Pictures library.\n You can go to Settings page to turn off chart thumbnails.\n  Hints on message streams\n Some message streams, for example, the streams in feed panel of Main page and the streams in stock stream page, support pull-to-refresh. Scroll down a little bit and scroll back to top and see what happens :)\n However, not all streams support this feature. For example, the streams under inbox / sent pivots need refreshing manually.\n  Hints for stock stream page\n Sentiment history and message volume graphs are updated daily.\n Price history graph is real-time, and you can always tap on it to have it refreshed (without refreshing the whole page).\n Slide on the bar on the right of \u0026ldquo;price history\u0026rdquo; title can change the scope of price history graph, varying from \u0026ldquo;1 day\u0026rdquo; to \u0026ldquo;5 years\u0026rdquo;.\n  How can I get rid of app ads?\nGo to account panel (the fourth panel on app landing screen), expand bottom menu bar, click \u0026ldquo;app settings\u0026rdquo;, and toggle off \u0026ldquo;Show advertisements\u0026rdquo;. Ads will be turned off for a week. There is no in-app purchase required. However, if at all possible, please enable ads on to support the developer.\nChange Log 2/14/2015\n Improved program stability in face of StockTwits outages  2/8/2015\n Added feature to view / save full charts in app Added feature to like / unlike messages Now able to reply any message besides the original post Renovated message display interface Renovated user profile page  1/30/2015\nAs a partner of StockTwits, we now offer many new features that our competitors do not have:\n Added sentiment history chart Added message volume chart Added Yahoo! price history chart Added real-time stock price info display Added auto-suggestion support on search page Added support for displaying latest streams Renovated account panel; more parameters modifiable Pull-to-refresh on most stream lists Improved recent list UI improvements And more!  01/19/2015\n Bug fixes.  12/31/2014\n StockPulse is now partner of StockTwits! More partner-only data display will arrive soon! (As a side note, Partner-level API access crashes StockPulse WP on versions older than 0.3. Please upgrade to latest version to fix the problem.) Messages can display sentiment tag and chart thumbnail (can be switched off in settings). Improved detection of tickers in messages. Bug fixes.  12/30/2014 (Windows Phone)\n App renamed to \u0026ldquo;StockPulse\u0026rdquo; from \u0026ldquo;StockTweets\u0026rdquo;. UI improvements.  12/29/2014\n Added a toggle switch to turn off all ads in the app. Minor bug fixes.  12/28/2014\n First release build.  Future The app, at least for Windows Phone 8 version, is unlikely to be updated further. My enthusiasm for Windows Mobile / Windows Phone platform has run out.\nGallery                    ","iconClass":"fa-camera","objectID":"26ddca0e43edb1f4d051d914342dd91b","tags":["microsoft","project","csharp","app"],"title":"StockPulse for WP8 - a StockTwits client for WP8","type":"gallery","url":"/gallery/stockpulse-wp8/"},{"author":"xbu","categories":["microsoft","windows","ie","troubleshoot"],"content":"For very long time I have been creating RAM disk and pointing temp and cache dirs there to improve I/O performance and reduce unnecessary SSD writes. Since Windows 8, changing the cache location of IE (a.k.a. \u0026ldquo;Temporary Internet Files\u0026rdquo;) to a RAM disk could result in crashes of Metro (a.k.a. \u0026ldquo;Modern\u0026rdquo;) apps, which I didn\u0026rsquo;t figure out why until recently. The problem is also observable in Windows 10.\n\nA Microsoft forum post discussed troubleshooting the problem of \u0026ldquo;metro app crashes immediately after opening\u0026rdquo;. But it\u0026rsquo;s not the case here.\nSymptom Here is a list of apps I have found to be affected by the IE cache location:\nAmazon Kindle (appear to \u0026ldquo;crash\u0026rdquo; / flash exit) After starting, the app seems to minimize itself to taskbar, and if you click on it, it tries to load but goes minimized again. It crashes but does not exit. On Windows 10 it crashes and exits after staying in splash screen for a minute or so.\nRelated system error log\nSource: AppModel-State Failure to load the application settings for package AMZNMobileLLC.KindleforWindows8_stfe6vwa9jnbp. Error Code: 3 Source: AppHost App crashed with an unhandled Javascript exception. App details are as follows: Display Name:, AppUserModelId: \u0026lt;amznmobilellc .kindleforwindows8_stfe6vwa9jnbp=\\\u0026quot;\\\u0026quot;\u0026gt; Package Identity: PID:\u0026lt;14204\u0026gt;. The details of the JavaScript exception are as follows Exception Name:, Description: \u0026gt;, HTML Document Path:, Source File Name:, Source Line Number:\u0026lt;11\u0026gt;, Source Column Number:\u0026lt;59191\u0026gt;, and Stack Trace: ms-appx://amznmobilellc.kindleforwindows8/kindle-min.js:11:59191 Anonymous function() ms-appx://amznmobilellc.kindleforwindows8/kindle-min.js:11:55820 Global code .\u0026lt;/amznmobilellc\u0026gt;  Latermark (appear to \u0026ldquo;crash\u0026rdquo; / flash exit) The \u0026ldquo;appear-to-crash\u0026rdquo; behavior is the same as Kindle\u0026rsquo;s. I have been in touch with Latermark\u0026rsquo;s developer (who is very responsive) since I found the app did not work on my machine, and hopefully its next version will tell you some error instead of \u0026ldquo;flash exit\u0026rdquo; when such problem is triggered.\n[Update] After knowing the cause, the developer has made a page telling you \u0026ldquo;something unexpected happened\u0026rdquo; when this problem is triggered.\nRelated error event:\nApp crashed with an unhandled Javascript exception. App details are as follows: Display Name:, AppUserModelId: \u0026lt;23234cthedot.Latermark_hxggmq2sf9ec6!App\u0026gt; Package Identity:\u0026lt;23234cthedot.Latermark_3.0.0.0_neutral__hxggmq2sf9ec6\u0026gt; PID:\u0026lt;5248\u0026gt;. The details of the JavaScript exception are as follows Exception Name:, Description:, Source File Name:, Source Line Number:\u0026lt;257\u0026gt;, Source Column Number:\u0026lt;7\u0026gt;, and Stack Trace: ms-appx://23234cthedot.latermark/js/store.js:257:7 get(string) ms-appx://23234cthedot.latermark/js/latermark.js:77:7 _load() ms-appx://23234cthedot.latermark/js/latermark.js:72:5 Anonymous function() ms-appx://23234cthedot.latermark/js/latermark.js:108:3 Anonymous function() ms-appx://23234cthedot.latermark/js/latermark.js:2:2 Global code .  Nextgen Reader (cannot associate with accounts like Pocket) Nextgen Reader works fine until you try to link your accounts, for example, Pocket, to the app. An error toast notification will show up (like the picture above).\nHyper for YouTube (cannot play video) If you see some error message from the app Hyper for YouTube like the picture below, it may be caused by you changing the IE cache location.\nMetrotube (cannot play video) Similar behavior as Hyper for YouTube.\nAnalysis Windows 8\u0026frasl;8.1 Modern (\u0026ldquo;Metro\u0026rdquo;) apps need to access the IE cache location and they are forced to work under IE\u0026rsquo;s Enhanced Protection Mode. This requires the IE cache location to be inside a NTFS partition of a disk visible in Disk Management Console (diskmgmt.msc). Not all RAM disk drivers emulate their drives that way.\nFix The dumbest way is to change the IE cache location back to default (%USERPROFILE%\\AppData\\Local\\Microsoft\\Windows\\Temporary Internet Files).\nTo keep RAM disk AND have Metro apps work, there are two points to check:\n The RAMDrive must use NTFS filesystem, and The drive is accessible in Metro apps. In other words, Open \u0026ldquo;Run\u0026rdquo; dialog (Win+R) and type \u0026ldquo;diskmgmt.msc\u0026rdquo; to open the Disk Management Console, the RAMDrive drive should be visible there.  It\u0026rsquo;s easy to get the first point with most RAM disk software, but few support the second. One free RAM disk software that does so is SoftPerfect RAM Disk. One should choose NTFS filesystem AND enable \u0026ldquo;hard disk emulation\u0026rdquo;, although this dramatically reduces the RAM disk\u0026rsquo;s performance.\n","iconClass":"fa-pencil","objectID":"f309297b6acec1d7d20498e8ef649f50","tags":["microsoft","windows","ie","troubleshoot"],"title":"IE Cache Location and Metro App Crash","type":"article","url":"/article/ie-cache-location-ramdisk-metro-app-crash/"},{"author":"xbu","categories":["microsoft","outlook","css","firefox"],"content":"Outlook.com is a decent email service by Microsoft. I\u0026rsquo;ve been enjoying it and its past lives, but sometimes I feel the ad bar annoying\u0026hellip;\n\nThe ad bar is placed as right pane and doesn\u0026rsquo;t affect usage most of the time. Sometimes it showed interesting stuff. But sometimes it\u0026rsquo;s not cool. If the screen is not wide enough, the subject column is left with only 5 to 6-char width and the ad remains. Couldn\u0026rsquo;t MS provide an option to show the ad as a banner at the bottom of the page?\nTo reclaim space, I created a Stylish script (The script has been uploaded to userstyles.org.):\n@-moz-document domain(live.com) { #RightRailContainer {display: none;} .WithRightRail {right: 0 !important;} }  Effect But again, Outlook.com is an awesome service and if at all possible, don\u0026rsquo;t kill the ads.\nUpdate for new Outlook.com Outlook.com recently rolled out new interface which makes the original hack ineffective. The updated CSS hack, in turn, is as follows:\n@-moz-document domain(live.com) { /* For old Outlook.com */ #RightRailContainer {display: none;} .WithRightRail {right: 0 !important;} /* For new Outlook.com */ ._n_h {display: none; width: 0;} #primaryContainer div[style*=\u0026quot;right: 165px;\u0026quot;] {right:0 !important;} }  Because the AD element is neither named nor classified, a slightly complex selector is used. The effect looks like the following:\nUpdate for new Outlook.com Beta (Summer 2017) The ID and class of the ad DOM are now randomly generated strings. The hack no longer works.\n","iconClass":"fa-pencil","objectID":"865bb946c9daffad34f645fbd22ce225","tags":["microsoft","outlook","css","firefox"],"title":"Remove the AD of Outlook.com with Stylish","type":"code","url":"/code/remove-the-ad-of-outlook-com-with-stylish/"},{"author":"xbu","categories":["firefox","css"],"content":"Australis has been incorporated to release channel since Firefox 29, replacing title bar with tabs bar. One thing to be picky about is that there is a margin above tabs and it wastes vertical space.\n\nUpdates Update 3 The Stylish addon seems no longer maintained. Stylus seems a working alternative.\nUpdate 2 Since Firefox 53, two new compact themes have been introduced (read here). With these themes, the stylish hack is no longer needed.\nUpdate 1 For convenience the script has been added to userstyles.org.\nSolutions Solution 1 In Stylish add-on (https://addons.mozilla.org/en-US/firefox/addon/stylish/), create a new user script with the following content:\n:root[sizemode=\u0026quot;normal\u0026quot;] #titlebar { margin-bottom: -60px !important; }  and the gap will be removed.\nSolution 2 With some further search I found this post: http://forums.mozillazine.org/viewtopic.php?f=23\u0026amp;t=2813465 where \u0026ldquo;Gingerbread Man\u0026rdquo; posted another solution that is shorter but produces the same outcome:\n#TabsToolbar { margin-top: 0px !important; }  I prefer this solution.\nOutcome Before:\nAfter:\n","iconClass":"fa-pencil","objectID":"cdae2b64ee1fb0a5888a79b91950237c","tags":["firefox","css"],"title":"Reduce Margin between Tabs and Title Bar in Firefox Australis","type":"code","url":"/code/reduce-margin-between-tabs-and-title-bar-in-firefox-australis/"},{"author":"xbu","categories":["purdue","c"],"content":"So far my assignment grading system uses a legacy (and buggy) library written by some former TA to check memory leakage of student programs. Now that it\u0026rsquo;s time for a major OS upgrade (Ubuntu 14.04), this solution exposed more bugs. Time to retire it and make my own ones.\n\nThe Problem Given some buggy student code, how can you write a program that can tell whether there is memory leaked or not without human interference?\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(void) { char *p = malloc(12); *p = 'a'; //let's add some segfault *(p = NULL) = 'b'; return 0; }  Note that in the program, the segfault may prevent the automated process from going as planned.\nSolution A: Wrappers Use preprocessor to wrap malloc/calloc/realloc/free and take notes before calling the actual functions:\n#define malloc(x) gd_malloc(x, __LINE__, __FILE__) #define free(p) gd_free(p, __LINE__, __FILE__)  Notes for this approach:\n Must check to make sure that student code includes the header.  Solution B: Valgrind Use pipe to feed input, and call valgrind. Use regular expression to grab critical information from the report.\ncat input.txt | valgrind ./memleak  The valgrind information will be printed to stderr.\nA sample memleak report by valgrind:\n==1460== HEAP SUMMARY: ==1460== in use at exit: 20 bytes in 1 blocks ==1460== total heap usage: 1 allocs, 0 frees, 20 bytes allocated  A sample memfree report by Valgrind:\n==1464== HEAP SUMMARY: ==1464== in use at exit: 0 bytes in 0 blocks ==1464== total heap usage: 1 allocs, 1 frees, 20 bytes allocated ==1464== ==1464== All heap blocks were freed -- no leaks are possible  Known issues:\n Unacceptably slow, particularly because of the resource restriction (CPU and memory use, time limit, etc.) on the grading environment.\n Student could print to stderr and confound grading result.\n  Solution C: mtrace mtrace adds handlers to malloc/calloc/realloc/free and logs the events when they get called. One analyzes the log to decide if memory is leaked or not.\nNotes:\n Need to inject mtrace header.\n Need a log parser.\n  Solution D: my own library libmemchecker is a series of C libraries (or more precisely, hooks) that record the function calls of dynamic memory allocation, and parse the dump logs to analyze if the tested program leaks memory at exit.\nThey are lightweight and fit better in automated, jailed testing scenario than valgrind, which may use a lot more resources (exceeding resource limit) and run much more slowly (causing execution time-out).\nThere are three independent libraries in the repository and please read README.md for more details.\n GitHub Repository: https://github.com/xybu/libmemchecker\n Please note that they support only C source code, and it is unknown how it works on C++ programs.\n","iconClass":"fa-pencil","objectID":"6e9b9fe3956a0129618031c86f7f41bc","tags":["purdue","c"],"title":"Checking Memory Leakage of Student Programs","type":"code","url":"/code/a-simple-memory-leak-checker/"},{"author":null,"categories":["git","gitignore"],"content":"Generate .gitignore file from hundreds of templates for various Operating Systems, IDEs, and Programming Languages.\n","iconClass":"fa-link","objectID":"328682ea02a30d74e203da6f1fc49e58","tags":["git","gitignore"],"title":"gitignore.io - Online .gitignore Generator","type":"link","url":"/link/gitignore-io/"},{"author":"xbu","categories":["ubuntu","php","nginx","mysql","linux"],"content":"This tutorial introduces how to set up a LEMP (Linux + Nginx + MySQL + PHP-FPM) stack on Ubuntu Server from scratch.\n\n Update on Dec 24, 2015: added PHP7.0-FPM instructions.\n Upgrade to Latest Ubuntu Distro (Optional) If your server runs an older version of Ubuntu Server and you want to upgrade to the latest version, you will need to do the following with root permission:\n# get root permission sudo -s # update package lists apt-get update apt-get dist-upgrade # install update manager command-line tool apt-get install update-manager-core # start upgrade do-release-upgrade -d  Check Basic Settings Here are some basic configurations you need to do at the beginning.\nTime and Timezone # set up timezone sudo dpkg-reconfigure tzdata # synchronize time (requires ntpdate package) sudo apt-get install -y ntpdate sudo ntpdate ntp.ubuntu.com  System Locale If you don\u0026rsquo;t have Unicode as default locale, something could go wrong when like, you add PPAs / repositories or use some Python scripts. There are workarounds for that, but why not Unicode? So check the locale first. You may want to adjust the locale string to your owns.\n# print locale information locale -a # generate English UTF-8 locale sudo locale-gen en_US.UTF-8 export LANG=en_US.UTF-8 # if other UTF-8 locales are available, simply switch to them. # For example, # export LANG=C.UTF-8 # set default locale to English (US) touch /etc/default/locale echo LANG=\u0026quot;en_US.UTF-8\u0026quot; \u0026gt; /etc/default/locale echo LANGUAGE=\u0026quot;en_US:en\u0026quot; \u0026gt;\u0026gt; /etc/default/locale  This will fix errors like\nUnicodeDecodeError: 'ascii' codec can't decode byte 0x* in position *: ordinal not in range(128)  Some Necessary Packages Before proceeding, do a sudo apt-get update \u0026amp;\u0026amp; sudo apt-get upgrade to upgrade all current packages to latest.\nThen install the following packages so that you can add apt repositories (i.e., use add-apt-repository command later).\nsudo apt-get install python-software-properties software-properties-common  GPG Error: NO_PUBKEY? This GPG error might happen if you are upgrading to Ubuntu 14.04 LTS:\nW:GPG error:http://archive.ubuntu.com trusty-updates Release: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 40976EAF437D05B5 NO_PUBKEY 3B4FE6ACC0B21F32  To solve this simply import the public keys listed in the error prompt.\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 40976EAF437D05B5 sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 3B4FE6ACC0B21F32  After importing the keys, rerun the apt-get command. If aptitude says it requires installation of \u0026ldquo;untrusted\u0026rdquo; packages, clean the cache as this topic says.\nSetup LEMP Stack Note that this section only addresses installation, not configuration. Here is a more comprehensive tutorial about setting up LEMP stack.\nInstall Latest Nginx Ubuntu by default seldom ships the latest version of Nginx. To use the latest stable version, according to http://wiki.nginx.org/Install\nsudo -s # Use root permission add-apt-repository ppa:nginx/stable apt-get update apt-get install nginx-extras  Install Latest MySQL The default version of MySQL on Ubuntu 14.04 LTS is 5.5, but MySQL 5.6 is actually available through universe channel:\nsudo apt-get install mysql-client-5.6 mysql-server-5.6  It will prompt you to enter MySQL root password after installation.\nInstall Latest PHP-FPM Note that add-apt-repository is broken on non-UTF-8 locales. For workaround, refer here.\nIf you want PHP 5 (5.6) only,\nsudo add-apt-repository ppa:ondrej/php5-5.6 sudo apt-get install php5-common php5-fpm php5-dev php5-mysql php5-curl php5-geoip php5-gd php5-intl php-pear php5-imagick php5-imap php5-mcrypt php5-ming php5-ps php5-pspell php5-recode php5-snmp php5-sqlite php5-tidy php5-xmlrpc php5-xsl php5-apcu  If you want PHP 7 only,\nsudo add-apt-repository ppa:ondrej/php-7.0 sudo apt-get install php7.0-fpm php7.0-mysql php7.0-json # and more you may need  If you need PHP 5 and PHP 7 coexist,\nsudo add-apt-repository ppa:ondrej/php # and install packages  And for a performance boost, don\u0026rsquo;t forget to enable Zend OPcache and APCu in php.ini, which can be checked by inspecting the output of command php -v, and calibrate the time on the server. To enable OPcache and APCu, refer to \u0026gt;this article\u0026lt;. If higher performance is desired, one may prefer Facebook HipHop VM to official Zend PHP Engine.\nOther Packages Other packages that may be useful including\n smtp server packages like ssmtp, if you need smtp on your server\n access control package like acl, if you need more concrete permission control\n  Secure the Server Secure PHP Inside the effective php.ini on the host (For PHP5-FPM, normally at \u0026ldquo;/etc/php5/fpm/php.ini\u0026rdquo;), find the param cgi.fix_pathinfo and change its value to 0. This post discusses how an attacker can initiate an attack by exploiting this param.\ncgi.fix_pathinfo=0  ufw ufw is the \u0026ldquo;firewall\u0026rdquo; shipped by Ubuntu. Here is a comprehensive tutorial: http://www.thefanclub.co.za/how-to/how-secure-ubuntu-1204-lts-server-part-1-basics\nDepending on the jobs of your server, you need to grant in / out access to different ports. Besides, be careful if your connection to the server depends on a port. Making changes effective before allowing that port connection may result in termination of your existing connection. In particular, if you use a non-default SSH port, be 100% sure to enable it before making ufw changes effective. (For how to change the SSH port, check the related section near the end of this post.)\nFor example, for a web server that also sends emails and accepts ssh connection, the following ports should be open:\n# If you haven't installed ufw sudo apt-get install ufw # YOUR_CUSTOM_SSH_PORT is either \u0026quot;ssh\u0026quot; (alias for 22) or the port number. sudo ufw allow YOUR_CUSTOM_SSH_PORT sudo ufw allow http sudo ufw allow https sudo ufw allow smtp sudo ufw allow out 53  Pay attention that ufw may disable outgoing ports which results in failures of commands like apt-get or git because they cannot connect to DNS server. Enabling outgoing traffic on port 53 should solve this.\nAnother issue is that ufw disables most outgoing traffic, including traffic between different ports of the same machine, making Wordpress plugins like Akismet and JetPack behave incorrectly.\nTo enable outgoing traffic,\niptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT  To make sure ufw not disable the server itself:\nsudo ufw allow in from YOUR_SERVER_IP_ADDR  Some OpenVZ-contained ipv6 hosts may have issues with ufw, here is an article discussing the solution.\nModSecurity To install ModSecurity on Nginx one needs to start from compiling the code as standalone module. The guides are available at https://github.com/SpiderLabs/ModSecurity/wiki/Reference-Manual#Installation_for_NGINX.\nBefore you start, beware that the compilation process may complain \u0026ldquo;configure: error: couldn\u0026rsquo;t find APXS\u0026rdquo; because it relies on this Apache module. I don\u0026rsquo;t want Apache at all, so I personally skip this step\u0026hellip;\nModSecurity requires the following packages to compile:\nsudo apt-get install libxml2 libxml2-dev libxml2-utils libaprutil1 libaprutil1-dev sudo apt-get install libpcre-ocaml-dev autoconf make automake libtool sudo apt-get install build-essential git libpcre3 libpcre3-dev libpcrecpp0 libssl-dev zlib1g-dev # should be comprehensive enough  Nginx: HttpLimitReqModule ngx_http_limit_req_module (HttpLimitReqModule) is a Nginx module that works similar to Apache\u0026rsquo;s ModEvasive. You can use it to limit the number of requests for a given session (per a defined key), thereby reducing the possibility of server overload or DDoS attacks. When the number of session requests exceeds the ceiling, a HTTP 503 error will be returned.\nStep 1: Create a Limit zone sudo vim /etc/nginx/nginx.conf  Inside the http container, add\nlimit_req_zone $binary_remote_addr zone=one:10m rate=2r/s;  For example,\nhttp { limit_req_zone $binary_remote_addr zone=one:10m rate=2r/s; # YOUR ORIGINAL CONTENT # FOLLOWS }  where one is the name of the zone, and 10m means that the storage is 10MB in size. Each state marked by $binary_remote_addr takes 64B, so 10MB should be plenty for guests. The rate is set to be 2 requests per second; other units include r/m, etc.\nStep 2: Make the Limit zone effective Add the limit zone to the http {}, server {}, location {} containers where you want it to be effective:\nlimit_req zone=one burst=6;  In each second, the third (2+1, where 2 is the max number of requests in the specified time span, which in our example, is rate=2r/s) to sixth (because burst=6) requests, if any, will be queued, and if there are more than six requests, a HTTP 503 will be returned.\nMore details can be found at Nginx\u0026rsquo;s document page http://nginx.org/en/docs/http/ngx_http_limit_req_module.html.\nUse a Non-Default Port of SSH Connection To change the port number used by sshd,\nsudo vim /etc/ssh/sshd_config  Find the line Port 22 and change the \u0026ldquo;22\u0026rdquo; to the port number you want to use.\nYou can also disable root login there.\nAdd Users and Set File Access Control Permissions There is no universal command for this step, but the target is to isolate tasks to reduce the possibility of compromising.\nHousekeeping Finally there is some housekeeping work.\nsudo apt-get autoremove sudo apt-get autoclean  That\u0026rsquo;s it!\nMore Readings  http://konradpodgorski.com/blog/2013/10/23/guide-how-to-configure-server-for-symfony/ ","iconClass":"fa-pencil","objectID":"81fa89719ee9ebd04aee92317b40d87a","tags":["ubuntu","php","nginx","mysql","linux"],"title":"Set up Ubuntu + PHP7 + Nginx + MySQL Stack","type":"article","url":"/article/setting-up-a-ubuntu-server/"},{"author":"xbu","categories":["php","framework","comparison"],"content":"I have a few projects that need PHP server side. After a few trials to write classes myself I realized there must be wheels already invented (\u0026ldquo;frameworks\u0026rdquo;). After some research I found myself prefer micro-frameworks strongly over some full-fledged frameworks. And further research did give me some interesting names.\n\nThe first thing to mention is that I found a nearly full list of PHP micro-frameworks (though the data not quite up-to-date) at http://phptrends.com/category/9\nMy Requirements It\u0026rsquo;s always best to be clear what are the must-have features, and what are the bonuses.\nFor my projects, the basic, overlapping functions are\n User log-in, register, password retrieval functions Cron for scheduling task  Some bonuses can be\n OAuth2 client support (even as an extension) for facebook, Google, Microsoft account log in Caching (strong bonus) Database API built-in AJAX responses (weak bonus) Template support  Not quite attractive but may be nice:\n JSON support (not attractive because PHP can handle it very well)  Baseline: while I can write code to cover all my needs, using a framework should substantially reduce my workload and increase levels of maintainability and security.\nGeneral-Purpose Micro-frameworks Code is from each one\u0026rsquo;s official documents unless noted.\n1. Slim Available at http://www.slimframework.com/, Slim seems to be one of the most popular players in this category. The hello world looks simply. You just need to define the routes and run the object.\n$app = new \\Slim\\Slim(); $app-\u0026gt;get('/hello/:name', function ($name) { echo \\\u0026quot;Hello, $name\\\u0026quot;; }); $app-\u0026gt;run();  The object-oriented style is a minor bonus for me.\nIt looks like there is an example for facebook integration: https://github.com/tuupola/slim-ar-facebook\nAnother rough example is at: http://help.slimframework.com/discussions/problems/824-facebook-api-using-slim-framework\nNotable: support for caching, error handling, and middle ware. Written in object-oriented style.\nLast Update: Nov 29, 2013\n2. Flight Available at http://flightphp.com/\nrequire 'flight/Flight.php'; Flight::route('/', function(){ echo 'hello world!'; }); Flight::start();  Notable: supports JSON requests/responses. Caching.\nLast Update: Jan 17, 2014 (and the update is too frequent to be considered a bonus in my opinion)\n3. Wave Available at http://www.waveframework.com/\nMuch more powerful. What makes this framework notably different from others is its built-in API handler functionality.\nNotable: MVC; caching; XML, CSV, JSON, HTML, native PHP and other data formats as output; user permission control; built-in security layer; ajax handling; provides Nginx conf file besides Apache .htaccess.\nLast Update: Aug 18, 2013\n4. Fat-Free Framework (f3) Available at http://fatfreeframework.com/home\nNotable: caching; ORM data mapping (best if one needs to transform from one db product to another); plug-ins; SMTP wrapper; OpenID support; singleton support; Nginx support.\nI have been using F3 for a while and am happy with it by far. It is simple, and does not exert much restrictions to you. The speed is also impressive. I have made Opauth work with f3 so OAuth is also done.\nLast Update: Mar 19, 2014 (not frequently but shows the developer\u0026rsquo;s steady effort to this project)\n5. Jolt http://joltframework.com/\nA sample entry program in Jolt is like\n$app = new Jolt(); $app-\u0026gt;get('/hello/:name', function ($name) use ($app) { echo \\\u0026quot;Hello, $name\\\u0026quot;; }); $app-\u0026gt;listen();  which looks similar to the other ones.\nNotable: caching; error handling; middleware (sounds like a trimmed SlimΓÇª)\nLast Update: Jan 14, 2014\n6. Aura http://auraphp.com/\nIt is not a typical PHP framework, but \u0026ldquo;fully decoupled libraries, and truly independent packages\u0026rdquo;, as its homepage states. However, it has a Aura framework built in on Aura packages.\nAs of Feb 06, 2014, it is in beta for v2. Considering my time frame, I am afraid I can\u0026rsquo;t wait for its release version.\n7. Hydra https://github.com/sandulungu/hydra\nNotable: \u0026ldquo;strong\u0026rdquo; security in its feature list (don\u0026rsquo;t know how to verify at this stage); twig engine engine.\nLast Update: Jan 2013.\n8. Epiphancy https://github.com/jmathai/epiphany\nEpi::init('route'); getRoute()-\u0026gt;get('/', 'home'); getRoute()-\u0026gt;get('/contact', 'contactUs'); getRoute()-\u0026gt;run(); function home() { echo 'You are at the home page'; } function contactUs() { echo 'Send us an email at [foo@bar.com](mailto:foo@bar.com)'; }  Looks like it got a new update on its Github repo on Dec 25, 2013.\n9. Popcorn The fully-featured Pop framework has a tar ball of size 1.9MB. But the tar of its watered-down Popcorn framework has a size 39KB.\nDidn\u0026rsquo;t check it carefully so cannot comment now. At a glance it offers what other frameworks offer.\nLast Update: Jan 27, 2014\n10. Silex require_once __DIR__.'/../vendor/autoload.php'; $app = new Silex\\Application(); $app-\u0026gt;get('/hello/{name}', function($name) use($app) { return 'Hello '.$app-\u0026gt;escape($name); }); $app-\u0026gt;run();  Silex uses Symfony2 components, and Opauth has Silex support.\n11. FRAPI http://getfrapi.com/\n12. Phalcon http://phalconphp.com/en/\nWritten in C as a PHP extension, Phalcon eclipses others with its supreme performance but also offers the functionality a typical PHP micro framework can give. What it is missing is the utilities libraries like the Minify (in F3, this is part of Web class) and Image handler classes as seen in Wave and F3 frameworks. However, Phalcon provides much better helper components for data processing.\nIn one sentence, if one has time and energy to build the components he / she needs, and foresees the need for performance and scalability, choose Phalcon.\nComparison Wave framework and Silex seem the ones that provide most functions.\nBut it is much easier to implement small projects using f3 (Fat-Free Framework) ΓÇô things seem to be \u0026ldquo;just enough\u0026rdquo;.\nOther Job-Specific Micro-frameworks 1. Medoo http://medoo.in/\nAn one-file framework for database operations. First impression: slim and sexy.\n2. php-login http://www.php-login.net/\nA framework (from professional MVC to one-fine package) specially for user log-in operations.\n3. opauth http://opauth.org/\nOpauth provides a generic layer for oauth providers. Compared to Hybridauth to be mentioned below, it is much smaller in size, but the code needs a major renovation (already in progress in wip-1.0 branch). It has some examples to embed opauth in major PHP frameworks including Slim.\n4. oauth-php http://code.google.com/p/oauth-php/\n5. HybridAuth http://hybridauth.sourceforge.net/\nAt first glance, it looks like the ultimate social connector framework. It supports connection to more than 30 Oauth websites, and has plugins for CodeIgniter, Zend Framework, Yii, CakePHP, and Symfony frameworks available. However, I will need to do some work to have it co-work with my favorite micro-frameworks. But it seems the work is worth it.\nSome non-PHP frameworks that may relate This section goes somewhat off-topic, but may be useful if one is building mobile apps.\nSocialAuth https://code.google.com/p/socialauth/\nSocialAuth is a generic OAuth consumer for Android projects.\n","iconClass":"fa-pencil","objectID":"e5436be6a38f6fbe12f3a14b530e51df","tags":["php","framework","comparison"],"title":"A Comparison of PHP Micro-frameworks","type":"code","url":"/code/a-comparison-of-php-micro-frameworks/"},{"author":null,"categories":["git","markdown"],"content":"A free, open-source, online WYSIWYG Markdown editor based on Pagedown. Just open the website and start editing, and optionally sync your documents with Google Drive and Dropbox, or publish them on GitHub, Blogger, WordPress, etc.\n","iconClass":"fa-link","objectID":"2cc982715a2dd93275eff7b24a74985c","tags":["git","markdown"],"title":"StackEdit.io - an Online Markdown Editor","type":"link","url":"/link/stackedit-io/"},{"author":null,"categories":["font","titillium"],"content":"A simple, elegant, and web-friendly font licensed under SIL Open Font License, 1.1.\n","iconClass":"fa-link","objectID":"7d0529d23168057084882e58bfff15a3","tags":["font","titillium"],"title":"Titillium Web Font","type":"link","url":"/link/titillium-web-font/"},{"author":"xbu","categories":["purdue","autograding"],"content":" For historical curiosity, this page records the work of Autograder, an automated grading platform used in Purdue CS240 \u0026ldquo;Programming in C\u0026rdquo; course. Students submit code for grading and later receive grades. This platform encouraged students to try achieving best score and also greatly reduced TAs\u0026rsquo; workload. In Fall 2014 a new project gitlab-ag, based on GitLab, replaced Autograder.\nAutograder has been deprecated. The purpose of this page is to summarize the knowledge and experience gained from this project so that we make better things in the future.\n2014 Fall Autograder was rewritten bottom-up. We replaced a UML-based sandbox with Docker because the former occasionally fails on Linux x86-64 kernel. The UI is reconstructed with Twitter Bootstrap. The event queue is rewritten to take advantage of multi-core hardware.\nGitHub Repository: https://github.com/xybu/autograder\nWe stopped using Autograder because the course instructor is so busy that he did not manage to prepare lab assignments in advance enough for preparing test cases and grading scripts.\n2014 Spring Server / Web Interface:\n UI improvements.\n Improved self-maintenance capability.\n Added daily submission quota functionality (can be turned off). E.g., if the quota is 15, then students are allowed to submit at most 15 times per day. This can be used to discourage late start and reduce the burden of the grading system.\n  From instructors\u0026rsquo; perspective:\n Admin control panel for instructors. Most common administrative operations can be done through web interface rather than direct file operations, thus reducing the permission level granted to every TA. This should enhance the system stability especially when there are a number of TAs modifying the file system.\n Improved debug mode. Instead of printing everything (Fall 2013), only the information about where the student program goes wrong will be printed. So TAs should feel more comfortable with it.\n Removed the historical rule that \u0026ldquo;the total point for an assignment must be 100\u0026rdquo;. Now the instructors can set their own total grade like (\u0026ldquo;60 / 60\u0026rdquo; for an assignment).\n  From students\u0026rsquo; perspective:\n Added a general guidance page to introduce the system. No need to teach students how to use it in the first lab session.\n Student will see more info about his/her status for each assignment.\n  TODO list:\n OS update move dump to tmpfs \u0026ldquo;Regrade my last submission\u0026rdquo; How would a self-hosted Git server + hooked grading system work?  2013 Fall Changes in terms of system stability:\n Isolation of TA platform and student platform for performance, security, and flexibility.\n Modularized and standardized test scripts (e.g., file ops, segfault detection functions, etc.) that makes TAs write stable Autograder code more easily.\n  Changes for instructors side:\n Added debug mode: enabling debug mode gives TAs a lot more information about what happened in one grading session. TAs can diagnose student code and give incisive feedback. By default debug mode is off for students but on for TAs.\n Added support for manual offset: If one assignment needs manually grading (e.g., coding style grade), instructors write the grade for each student through an interface, and Autograder will collect those grades and add them to the gradebook. In Fall 2013 semester the grades of most assignments consisted of 80% of Autograder score and 20% of hand-graded score for coding standards.\n Added submission history: Autograder now records the score of all submissions from each student. This makes it a lot easier to respond to grade/source code retrieval requests from students.\n  Util scripts:\n Turn-In ID generator: generates massive turnin IDs and match them with the students in the roster\n Slacker finder: generates a list of student ids who do not submit a specified assignment\n Moss runner: generates and runs the command of Moss for you so you don\u0026rsquo;t need to come up with and issue long commands every time.\n  Changes for students side:\n UI improvements to provide more information in more beautiful ways.  What to do in the future:\n Students want Autograder to provide more detailed feedback, which reflects that they want it to become a tool for study, not just for grading. Should think about how to fulfill this demand in the future.\n Make a hierarchy of test cases. If test case A fails and test case B depends on A, then skip B.\n User role system so that different users (TAs, students) get different permissions of doing something. But no strong demand for this so far.\n Better workload management mechanism that encourages students to start early and reduces the workload on due date (Done in Spring 2014).\n  ","iconClass":"fa-pencil","objectID":"cee77c4b2dd6455917afa10736a6a680","tags":["purdue","autograding"],"title":"Purdue CS240 Autograder","type":"article","url":"/article/purdue-cs240-autograder/"},{"author":"xbu","categories":["windows","qemu","emulation","raspberry pi"],"content":" The USB-TTL cable I\u0026rsquo;m provided with doesn\u0026rsquo;t support Windows 8.x, which is super inconvenient. So I decided to make a virtual machine running Occidentalis so that I don\u0026rsquo;t have to work on the real Pi.\n \u0026ldquo;Occidentalis\u0026rdquo; is Adafruit\u0026rsquo;s Raspberry Pi educational distro. More details can be found here.\n Before I made everything from scratch, I did some research and found one article that already discussed emulating RPi on Linux x86-64, and it works. And I even found one packed emulator for Raspbian on Microsoft Windows (Many thanks!)\nUpdate: I have packed my customization to the Raspbian emulator and uploaded the whole stuff to SourceForge. Copyright belongs to whoever creates the original tools and software.\nBuild from scratch A brief guide if you want to build everything from scratch.\nInstalling QEMU for your OS. For Windows, I found this: http://qemu.weilnetz.de/ (owner: Stefan Weil)\nFor Linux (e.g., Debian or Ubuntu), the following packages are needed, as the article in soslug.org discussed:\n qemu qemu-user qemu-kvm-extras qemu-utils kvm-ipxe  Get \u0026ldquo;kernel-qemu\u0026rdquo; file Just follow the article in soslug.org.\nGet the system image file Ether Raspbian or Occidentalis.\nRun QEMU loading the image My customizations to the sourceforge project \u0026ldquo;Raspberry Pi emulation for Windows\u0026rdquo;:\n I used Occidentalis to replace Raspbian since the former better suits the need of a learner. I added some port forwarding in the command to run QEMU:  qemu-system-arm.exe -M versatilepb -cpu arm1176 -m 192 -hda Occidentalis_v02.img -kernel kernel-qemu -append \u0026quot;root=/dev/sda2\u0026quot; -net nic -net user,hostfwd=tcp::2222-:22,hostfwd=tcp::5800-:5800,hostfwd=tcp::5900-:5900  I forwarded VM port 22 to host port 2222 so that I can ssh into the VM by connecting to localhost:2222 and exchange files easily.\nI forwarded VM ports 5800 and 5900 to host ports 5800 and 5900, so after installing TightVNCServer on the VM, I can use TightVNC Viewer to get a decent desktop environment. Simply connect to localhost using TightVNC\u0026rsquo;s default port 5800 or 5900.\nThankfully again, how to install VNC Server on RPi is discussed in this article: http://elinux.org/RPi_VNC_Server\nThe emulator already runs faster than the real Pi, but things are still slow, and it seems the Internet connection is not quite stable inside QEMU VM. I don\u0026rsquo;t know how it goes on other machines.\nThere have been many updates since the Raspbian or Occidentalis image was released. So one might want to update the system:\nsudo apt-get update sudo apt-get -y upgrade  And because my course project was to write a simple C compiler on Raspberry Pi using yacc and lex, I also installed the related packages:\nsudo apt-get -y install byacc flex bison m4  I am quite happy with the customizations because the GUI is decent and the system runs faster than the real Pi. But unfortunately the GPIO of RPi cannot be emulated.\nAlternative Approach \u0026ndash; SSH An alternative solution to using USB-TTL cable: having your Pi send its IP address to your email when it starts up, and then you ssh into it. Here is an article discussing this approach.\n","iconClass":"fa-pencil","objectID":"481be350ca19f879b10339ca90bb735b","tags":["windows","qemu","emulation","raspberry pi"],"title":"Emulating Raspberry Pi with QEMU","type":"article","url":"/article/emulating-raspberry-pi-with-qemu/"}]