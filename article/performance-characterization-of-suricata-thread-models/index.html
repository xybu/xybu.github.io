<!doctype html>
<html class="no-js" lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <meta name="author" content="Xiangyu Bu">
        <meta name="description" content="Xiangyu&#39;s personal blog.">
        <meta name="keywords" content="xiangyu,bu,xbu,blog,tech,onedrived">
        <meta name="generator" content="Hugo 0.31.1" />

        <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
        <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">

        <link rel="stylesheet" href="/dist/theme.css">

        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.2.1/dist/instantsearch.min.css">
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.2.1/dist/instantsearch-theme-algolia.min.css">


        

        
        <title>Another Dimension  | Performance Characterization of Suricata&#39;s Thread Models</title>
    </head>
    <body class="bilberry-hugo-theme">
        
<nav class="permanentTopNav">

    <div class="container">
        <ul class="topnav">
            
                
                    <li><a href="/page/about/">About</a></li>
                
            
                
                    <li><a href="/page/resources/">Resources</a></li>
                
            
                
                    <li><a href="/page/projects/">Projects</a></li>
                
            
        </ul>

        

         <div id="search-box" class="search">
            <i class="fa fa-search"></i>
            <input id="search" type="text" placeholder="Search ...">
        </div>
        
    </div>
</nav>


        <header>
    <div class="container">
        <div class="logo">
            <a href="/" class="logo">
                
                    <img src="https://www.gravatar.com/avatar/661d6e52bcde90223b84e56c54c568f6?d=mm&size=200" alt="">
                

                <span class="overlay"><i class="fa fa-home"></i></span>
            </a>
        </div>
        <div class="titles">
            <h3 class="title"><a href="/">Another Dimension</a></h3>
            
                <span class="subtitle">Xiangyu&#39;s personal blog.</span>
            
        </div>

        
        <div class="toggler permanentTopNav">
        
            <i class="fa fa-bars" aria-hidden="true"></i>
        </div>
    </div>
</header>


        <div class="main container">
            
     
    <div class="article-wrapper u-cf single">
        
            <a class="bubble" href="/article/performance-characterization-of-suricata-thread-models/">
    <i class="fa fa-fw fa-pencil"></i>
</a>

<article class="default article">
    

    <div class="content">
    <h3><a href="/article/performance-characterization-of-suricata-thread-models/">Performance Characterization of Suricata&#39;s Thread Models</a></h3>
    <div class="meta">
        <span class="date moment">2017-12-24</span>

        
            <span class="categories">
                
                    <a href="/categories/project">project</a>
                
            </span>
        

        
            <span class="author"><a href="/author/xbu">xbu</a></span>
        
    </div>

    
        

<p><a href="/article/benchmarking-suricata-in-different-isolation-systems-using-tcpreplay/">In a previous project</a> my fellow <a href="https://www.cs.purdue.edu/people/graduate-students/asheoran/">Amit Sheoran</a> and I examined how well <a href="https://suricata-ids.org/">Suricata IDS</a> runs inside Docker container and virtual machine environments. In April 2017, we further examined Suricata&rsquo;s various thread models, as a project for Purdue CS525 Parallel Computing course. In this article we first introduce the thread models, and then compare them in terms of performance and resource utilization.</p>

<h2 id="suricata-s-multi-thread-architecture">Suricata&rsquo;s Multi-Thread Architecture</h2>

<p>Compared to <a href="https://www.snort.org/">Snort IDS</a>, the biggest feature of Suricata
is that it adopts multi-threaded design to achieve high performance. In a
high-level picture, the design consists of four <em>thread modules</em> and three
<em>runmodes</em>.</p>

<h3 id="thread-modules">Thread Modules</h3>

<p>A thread module can be seen as a type of work to process a packet. There are
four major thread modules:</p>

<ul>
<li>Packet acquisition &ndash; Acquires packets from network.</li>
<li>Decode and Stream Application layer &ndash; Decodes the data and handles TCP reassembly, etc.</li>
<li>Detection &ndash; Matches the decoded data against Rules.</li>
<li>Output &ndash; Deals with logging, and alerting.</li>
</ul>

<p><img src="/images/suricata-thread-model/fig1.png" alt="Suricata Packet Processing Pipeline" /></p>

<p>Each thread can execute one or more thread module, depending on the runmode configuration.</p>

<h3 id="runmodes">Runmodes</h3>

<p>Suricata supports multiple runmodes to handle incoming packets:</p>

<ul>
<li>Single &ndash; Single-threaded mode.</li>
<li>AutoFP &ndash; The task of processing a packet is pipelined to multiple stages. Each thread handles one stage, and there is at least one thread in a stage.</li>
<li>Workers – Multiple workers, each of which single-handedly processes the packets it acquires (i.e., each thread runs all thread modules).</li>
</ul>

<h4 id="autofp-mode">AutoFP Mode</h4>

<p>In AutoFP mode, multiple threads try to acquire packets, and then put the packets to next stage of the pipeline for further processing. We refer to threads on packet acquisition stage as packet acquisition threads (PAQ), threads decoding packets as decoders, etc.</p>

<p><img src="/images/suricata-thread-model/fig2.png" alt="Suricata autofp mode" /></p>

<h4 id="workers-mode">Workers Mode</h4>

<p>In &ldquo;workers&rdquo; mode, multiple threads can receive packets and the thread that receives the packet executes all thread modules to process the packet.</p>

<p><img src="/images/suricata-thread-model/fig3.png" alt="Suricata workers mode" /></p>

<h4 id="single-mode">Single Mode</h4>

<p>Single mode is equivalent to workers mode with one worker thread.</p>

<h2 id="test-methodology">Test Methodology</h2>

<p>We rely on <a href="https://github.com/xybu/cs590-nfv">the test environment setup we made in NFV project</a>, and tweak the following parameters in the Suricata config:</p>

<ul>
<li>Runmode = {autofp, workers}</li>
<li>Number of (packet capture threads, decoding threads) = (1, 1) to (16, 32).</li>
<li>Number of NICs</li>
</ul>

<p>against various levels of workload generated by iperf (which turned out not doing well) and TCPreplay, and then collect performance and resource usage metrics. Suricata runs on bare metal.</p>

<h3 id="testbed-spec">Testbed Spec</h3>

<p>Both sender and receiver hosts have the following hardware spec:</p>

<ul>
<li>CPU: 2x Intel Xeon E5-2620 v4 @ 2.10GHz, 2 Sockets, 8 Cores Per Socket with HT disabled.</li>
<li>RAM: 64 GB</li>
<li>NICs: Intel I-350 Gigabit Ethernet</li>
</ul>

<p>and runs Ubuntu Server 16.04.2 LTS. The tests were based on Suricata 3.2, but
there haven&rsquo;t been significant changes to its thread model as of Dec 2017.</p>

<h3 id="experiment-with-iperf">Experiment with iperf</h3>

<p>When using <a href="https://iperf.fr/">iperf</a>, we use multiple client-server pairs to
generate traffic, which can be pure TCP or UDP packets. We also tweak packet
size,  bandwidth, and number of parallel streams. Iperf server end runs on the
same machine as Suricata, and one NIC can be used by one or more iperf pair.</p>

<p><img src="/images/suricata-thread-model/fig4.png" alt="iperf experiment setup" /></p>

<p>However, there is one issue with iperf approach. In order to compare thread
models of Suricata, we need controllable, constant packets-per-second (pps)
workload during stress test. And since packet payload does not matter much to
Suricata and our NIC is 1Gbps, packets must be small. Due to TCP congestion
control, pps from iperf varies greatly over time and is beyond our control.</p>

<p>Figure 5 shows the number of packets generated by iperf over time for one of the
test runs. pps varies over time, but throughput (bps) is kept constant over
this entire duration. iperf automatically increases the packet size when packet
generation rate falls.</p>

<p><img src="/images/suricata-thread-model/fig5.png" alt="iperf does not generate constant pps" /></p>

<p>Since pps generated by iperf is neither constant nor controllable over time, the
total number of packets sent to Suricata for handling differs for each iteration
of the same test. Therefore, we cannot guarantee all packet drops are due to
Suricata, and data points generated by iperf cannot be used as a basis for
comparison. We resort to TCPreplay to generate workload instead.</p>

<h3 id="experiment-with-tcpreplay">Experiment with TCPreplay</h3>

<p>TCPreplay replays a trace file onto a NIC notwithstanding network condition, so
the behavior is reproducible across runs. We use the ISTS’12 trace introduced in
our previous Suricata project, <code>snort.log.1425823194</code>, as workload traffic. It
generates ~55.42 Mbps at 6264.04 pps for approx. 22 seconds. To generate more
workload, up to 16 instances of TCPreplay per NIC are run concurrently. As a
baseline, we verified that the testbed system is capable of handling peak
workload of 16 TCPreplay instances without packet drop. All reported drops are
therefore caused by Suricata.</p>

<p><img src="/images/suricata-thread-model/fig6.png" alt="TCPreplay experiment setup" /></p>

<h2 id="evaluating-performance-and-resource-usage">Evaluating Performance and Resource Usage</h2>

<p>The result is kind of surprising.</p>

<h3 id="result-of-autofp-mode">Result of AutoFP Mode</h3>

<h4 id="scalability">Scalability</h4>

<p>Figure 7a shows the comparison of Suricata performance, in terms of the number
of packets decoded vs. packets dropped, with 1 PAQ and 1, 2 and 4 decoders. It
can be seen that performance does not scale with the number of decoders &ndash;
4 decoders do not do better than 1 decoder at 16X workload, while there is no
resource bottleneck. This is also the case when 2 PAQ threads are used, as
shown by Figure 7b.</p>

<p><img src="/images/suricata-thread-model/fig7a.png" alt="autofp Result with 1PAQ, 1-4 Decoders" /></p>

<p><img src="/images/suricata-thread-model/fig7b.png" alt="autofp Result with 2PAQs, 1-4 Decoders" /></p>

<p>Comparing the two plots vertically, we see that performance does not scale with
the number of PAQ threads, either.</p>

<h4 id="resource-usage">Resource Usage</h4>

<p>Figure 8a shows the CPU usage and the number of packets processed by Suricata in
autofp mode with 8X load. CPU usage increases roughly linearly to the number of
packet acquisition threads (PAQ); however, this does not translate to
performance gain. RAM usage (not shown in the figure) increases sub-linearly and
is not a bottleneck. The pattern shows again on 16X load.</p>

<p><img src="/images/suricata-thread-model/fig8a.png" alt="autofp resource usage w.r.t. PAQs, 1 Decoder" /></p>

<p>Worrying that it could be a bottleneck to have only one decoder thread, we
plotted figure 8b where there are two decoders. We see that CPU usage drops on
nodes PAQ={3, 4} but increases on nodes PAQ={1, 2}.</p>

<p><img src="/images/suricata-thread-model/fig8b.png" alt="autofp resource usage w.r.t. PAQs, 2 Decoders" /></p>

<p>It&rsquo;s also noteworthy that with more threads, Suricata becomes less capable to
handle the traffic it manages to handle with fewer threads.</p>

<h4 id="multiple-nics">Multiple NICs</h4>

<p>Figure 9 shows the performance in autofp mode with 2 NICs. Compare it with
Figure 8a and we see that Suricata does not handle more packets even though
the traffic could have been dealt with &ldquo;with more freedom&rdquo;. Besides, CPU usage
almost doubles at nodes PAQ={2, 3, 4}, but more than half of total traffic
is dropped.</p>

<p><img src="/images/suricata-thread-model/fig9.png" alt="autofp result with two NICs" /></p>

<h4 id="summary">Summary</h4>

<p>We see that on autofp runmode:</p>

<ul>
<li>Performance does not scale with the number of packet acquisition threads or
decoder threads;</li>
<li>CPU usage increases almost linearly with the number of PAQ threads, but it
does not translate to performance improvement;</li>
<li>Performance does not improve when traffic is distributed on different NICs.</li>
</ul>

<p>In all data points, we never see a speedup &gt; 1.13 (in terms of packets
processed) for autofp mode.</p>

<h3 id="results-workers-mode">Results &ndash; Workers Mode</h3>

<p>Workers mode differs from autofp mode in that a packet, once captured, is never
transferred to another thread for processing. So in workers mode, there is no
distinction between PAQ threads and decoder threads. It&rsquo;s verified both from
code and from experiment that in this mode, Suricata takes the number PAQ
threads from config and ignores the number of decoder threads.</p>

<p>As seen from figure 10, performance gets worse as the number of worker threads
increases, while CPU usage increases. However, CPU usage seems capped to 200%.</p>

<p><img src="/images/suricata-thread-model/fig10.png" alt="workers mode result with 1 decoder and 1-4 PAQs" /></p>

<p>Figure 11 is almost the same as figure 10. This confirms that the number of
decoder threads config is not used in workers mode.</p>

<p><img src="/images/suricata-thread-model/fig11.png" alt="workers mode result with 2 decoders and 1-4 PAQs" /></p>

<p>Figure 12 shows the performance in worker mode with 2 NICs. The total number
of worker threads is <code>#NICs * #PAQs</code>, but still, about half of total traffic
is dropped no matter how we increase the number of threads.</p>

<p><img src="/images/suricata-thread-model/fig12.png" alt="workers mode result with two NICs" /></p>

<h4 id="summary-1">Summary</h4>

<p>Performance of the system gets worse as the number of threads increases, but
resource usage does not increase as sharply as in autofp mode. In all the data
points, the best speedup we see is 1.28 for workers mode.</p>

<h2 id="analyzing-runmodes-with-intel-vtune">Analyzing Runmodes with Intel vTune</h2>

<p>Intel vTune is a tool for software performance analysis. We used it to further
analyze the unexpected result of Suricata thread models.</p>

<h3 id="autofp-mode-1">AutoFP Mode</h3>

<p>The analysis was based on running Suricata with 8 PAQ threads and 4 decoder
threads, 8X workload, and 2 NICs.</p>

<p>It confirmed what we observed from the experiment that AutoFP mode has higher
level of concurrency compared to Workers mode. The average CPU usage is ~1000%.
However, recall that the performance does not improve even though more resource
is used.</p>

<p><img src="/images/suricata-thread-model/vtune_suricata_autofp_thread_concurrency.png" alt="Suricata shows low degree of concurrency in autofp mode." /></p>

<h4 id="contentions">Contentions</h4>

<p>With the help of Locks and Waits analysis of Intel vTune, we see that the
majority of CPU resource is spent on <code>poll()</code>. The second point of contention
is a condition variable to receive packets from the queue.</p>

<p>This is also reflected in the lower part of the screenshot. The 16 PAQ threads
(&ldquo;RX&rdquo; threads) are busy polling I/O events, and the worker threads (&ldquo;W&rdquo; threads)
are mostly idle. The load is not balanced in neither PAQ threads nor decoder
threads.</p>

<p><img src="/images/suricata-thread-model/vtune_suricata_autofp_contentions.png" alt="Threads shows high level of contentions in autofp mode." /></p>

<h3 id="workers-mode-1">Workers Mode</h3>

<p>Intel vTune confirmed that Workers mode had poor degree of thread concurrency
and barely used more than two cores during its execution. The following
screenshots are from analyzing Suricata with 8 workers, 8X workload, and 2 NICs.
Note that Suricata creates 8 workers for each NIC, so there are 16 workers in
total.</p>

<p><img src="/images/suricata-thread-model/vtune_suricata_workers_thread_concurrency.png" alt="Suricata shows low degree of concurrency in workers mode." /></p>

<h4 id="contentions-1">Contentions</h4>

<p>We see that the mutex to control fetching flows from hash is a major point of
contention. About 300 seconds out of ~360 seconds’ execution is spent here.
Besides, the load among the 16 workers (8 workers per NIC) is highly
imbalanced, even though the TCPreplay processes provide same load.</p>

<p><img src="/images/suricata-thread-model/vtune_suricata_workers_imbalanced_load.png" alt="The workload is highly imbalanced among workers." /></p>

<h2 id="conclusion">Conclusion</h2>

<p><strong>While more threads lead to higher resource usage (particularly in autofp mode),
they do not translate into better performance for Suricata.</strong> From what we
observed, neither multi-thread modes of Suricata scale to the number of
available cores:</p>

<ul>
<li>AutoFP mode (Speedup &lt;= 1.13)

<ul>
<li>Trivial to no speedup with increased number of PAQ or decoder threads.</li>
<li>Exhibits linear CPU usage increase, however, by wasting most of CPU cycles in polling.</li>
</ul></li>
<li>Workers mode (Speedup &lt;= 1.28)

<ul>
<li>Exhibits worse performance than AutoFP mode but uses less resource.</li>
<li>Hardly uses more than two CPU cores due to mutex contention.</li>
</ul></li>
</ul>

<p>And neither modes scale to the number of NICs.</p>

<p>The multi-thread design does not give Suricata the scalability it wants. To
improve performance, redesigning and benchmarking a new thread model is
imperative and contentions must be reduced by as much as possible.</p>

    
</div>

    
    
    <div class="tags">
        <i class="fa fa-tags"></i>
        
            <a href="/tags/purdue">purdue</a>
        
            <a href="/tags/networking">networking</a>
        
            <a href="/tags/project">project</a>
        
            <a href="/tags/suricata">suricata</a>
        
            <a href="/tags/benchmark">benchmark</a>
        
    </div>
    


</article>

        
    </div>

    <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "xbu" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

     

        </div>

        <footer>
    <div class="container">
        <div class="recent-posts">
            <strong>Latest posts</strong>
                <ul>
                
                    <li>
                        <a href="/article/performance-characterization-of-suricata-thread-models/">Performance Characterization of Suricata&#39;s Thread Models</a>
                    </li>
                
                    <li>
                        <a href="/article/benchmarking-suricata-in-different-isolation-systems-using-tcpreplay/">Benchmarking Suricata in Different Isolation Systems Using TCPreplay</a>
                    </li>
                
                    <li>
                        <a href="/link/hack-font/">Hack Font</a>
                    </li>
                
                    <li>
                        <a href="/quote/andy-grove-paranoid/">Only the Paranoid Survive</a>
                    </li>
                
                    <li>
                        <a href="/article/onedrived/">onedrived - Microsoft OneDrive client for Linux</a>
                    </li>
                
                    <li>
                        <a href="/article/gitlab-ag/">gitlab-ag - Combining Git and Autograding</a>
                    </li>
                
                    <li>
                        <a href="/gallery/stockpulse-wp8/">StockPulse for WP8 - a StockTwits client for WP8</a>
                    </li>
                
                </ul>
        </div>

        <div class="categories">
            <strong>Categories</strong>

            
                <ul>
                
                    <li>
                        <a href="/categories/hack">Hack (1)</a>
                    </li>
                
                    <li>
                        <a href="/categories/project">Project (8)</a>
                    </li>
                
                    <li>
                        <a href="/categories/resource">Resource (4)</a>
                    </li>
                
                    <li>
                        <a href="/categories/troubleshooting">Troubleshooting (1)</a>
                    </li>
                
                    <li>
                        <a href="/categories/tutorial">Tutorial (2)</a>
                    </li>
                
                </ul>
            
        </div>

        <div class="social-media">
            <strong>Social media</strong>

            
                <a href="https://www.facebook.com/xiangyu.bu" target="_blank"><i class="fa fa-facebook"></i></a>
            
            
            
            
            
                <a href="https://www.instagram.com/xybu92/" target="_blank"><i class="fa fa-instagram"></i></a>
            
            
            
            
            
                <a href="https://github.com/xybu" target="_blank"><i class="fa fa-github"></i></a>
            
            
                <a href="https://bitbucket.org/xybu/" target="_blank"><i class="fa fa-bitbucket"></i></a>
            
        </div>
    </div>
</footer>

<div class="credits">
    <div class="container">
        <div class="copyright">
             &copy; 2017 Xiangyu Bu. <br />
            Unless otherwise noted, licensed under <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0 License</a>.
        </div>
        <div class="author">
            Theme by <a href="https://github.com/Lednerb/bilberry-hugo-theme" target="_blank">Lednerb</a>
        </div>
    </div>
</div>


        
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-47913300-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>


        
        
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$','$'], ['\\(','\\)']]}
        });
</script>

        

        <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.19.1/moment-with-locales.min.js" integrity="sha256-TbOIe++NbC9P3KTtUMJ5wcROlBdnRqrPleLdpPg3xxE=" crossorigin="anonymous" type="application/javascript"></script>
        <script src="/dist/theme.js" type="application/javascript"></script>

        

        <script>
            $(document).ready(function() {
                $(".moment").each(function() {
                    $(this).text(
                        moment( $(this).text() )
                            .locale( "en" )
                            .format('LL')
                    );
                });

                $(".footnote-return sup").html("[return]")
            })
        </script>

        
            
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.29.0/autocomplete.jquery.min.js" integrity="sha256-qUqrH6CxKeU+3ClSSiq0GGnYjoKmfLhNO4tFoTCay5c=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/algoliasearch/3.24.5/algoliasearch.min.js" integrity="sha256-vUvLcn3X0cXhote4PNwW6d+fzjJR0hoD+yGFeVaElew=" crossorigin="anonymous"></script>

<script>
    var client = algoliasearch("QWH90AJ7UA", "2b55d53047105f6dd3e8d30f7aadc3e9");
    var index = client.initIndex("xbu_me_index");

    $('#search').autocomplete({ hint: false, autoselect: true, debug: false },
      [
        {
          source: $.fn.autocomplete.sources.hits(index, { hitsPerPage: 5 }),
          displayKey: function(suggestion) {
            return suggestion.title || suggestion.author
          },
          templates: {
            suggestion: function(suggestion) {
                return "<span class='entry " + suggestion.type + "'>"
                      + "<span class='title'>" + suggestion.title + "</span>"
                      + "<span class='fa fa-fw " + suggestion.iconClass + "'></span>"
                  + "</span>"
                ;
            },
            empty: function() {
              return "<span class='empty'>Nothing found.</span>"
            },
            footer: function() {
              return '<div class="branding">Powered by <img src="https://www.algolia.com/static_assets/images/press/downloads/algolia-logo-light.svg" /></div>'
            }

          },
        }
      ])
      .on('autocomplete:selected', function(event, suggestion, dataset) {
        window.location = (suggestion.url);
      })
      .keypress(function (event, suggestion) {
        if (event.which == 13) {
          window.location = (suggestion.url);
        }
      });
</script>

        


    </body>
</html>
