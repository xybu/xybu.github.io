<!doctype html>
<html class="no-js" lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <meta name="author" content="Xiangyu Bu">
        <meta name="description" content="Xiangyu&#39;s personal blog.">
        <meta name="keywords" content="xiangyu,bu,xbu,blog,tech,onedrived">
        <meta name="generator" content="Hugo 0.31.1" />

        <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
        <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">

        <link rel="stylesheet" href="/dist/theme.css">

        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.2.1/dist/instantsearch.min.css">
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.2.1/dist/instantsearch-theme-algolia.min.css">


        
        <title>Another Dimension  | Performance Characterization of Suricata&#39;s Thread Models</title>
    </head>
    <body class="bilberry-hugo-theme">
        
<nav class="permanentTopNav">

    <div class="container">
        <ul class="topnav">
            
                
                    <li><a href="/page/about/">About</a></li>
                
            
                
                    <li><a href="/page/resources/">Resources</a></li>
                
            
                
                    <li><a href="/page/projects/">Projects</a></li>
                
            
        </ul>

        

         <div id="search-box" class="search">
            <i class="fa fa-search"></i>
            <input id="search" type="text" placeholder="Search ...">
        </div>
        
    </div>
</nav>


        <header>
    <div class="container">
        <div class="logo">
            <a href="/" class="logo">
                
                    <img src="https://www.gravatar.com/avatar/661d6e52bcde90223b84e56c54c568f6?d=mm&size=200" alt="">
                

                <span class="overlay"><i class="fa fa-home"></i></span>
            </a>
        </div>
        <div class="titles">
            <h3 class="title"><a href="/">Another Dimension</a></h3>
            
                <span class="subtitle">Xiangyu&#39;s personal blog.</span>
            
        </div>

        
        <div class="toggler permanentTopNav">
        
            <i class="fa fa-bars" aria-hidden="true"></i>
        </div>
    </div>
</header>


        <div class="main container">
            
     
    <div class="article-wrapper u-cf single">
        
            <a class="bubble" href="/article/performance-characterization-of-suricata-thread-models/">
    <i class="fa fa-fw fa-pencil"></i>
</a>

<article class="default article">
    

    <div class="content">
    <h3><a href="/article/performance-characterization-of-suricata-thread-models/">Performance Characterization of Suricata&#39;s Thread Models</a></h3>
    <div class="meta">
        <span class="date moment">2017-12-24</span>

        
            <span class="categories">
                
                    <a href="/categories/project">project</a>
                
            </span>
        

        
            <span class="author"><a href="/author/xbu">xbu</a></span>
        
    </div>

    
        

<p>(The article is still under construction.)</p>

<h1 id="performance-characterization-of-suricata-s-thread-models">Performance Characterization of Suricata&rsquo;s Thread Models</h1>

<p><a href="/article/benchmarking-suricata-in-different-isolation-systems-using-tcpreplay/">In a previous project</a> my fellow <a href="https://www.cs.purdue.edu/people/graduate-students/asheoran/">Amit Sheoran</a> and I examined how well <a href="https://suricata-ids.org/">Suricata IDS</a> runs inside Docker container and virtual machine environments. In April 2017, we further examined Suricata&rsquo;s various thread models, as a project for Purdue CS525 Parallel Computing course. We&rsquo;ll first introduce the thread models, and compare them in terms of performance and resource utilization.</p>

<h2 id="suricata-s-multi-thread-architecture">Suricata&rsquo;s Multi-Thread Architecture</h2>

<p>Compared to <a href="https://www.snort.org/">Snort</a>, the biggest feature of Suricata is that it adopts multi-threaded design &ldquo;to achieve high performance&rdquo;. In a high-level picture, the design consists of four thread modules and three runmodes.</p>

<h3 id="thread-modules">Thread Modules</h3>

<p>A thread module can be seen as a type of work to process a packet. There are four major thread modules:</p>

<ul>
<li>Packet acquisition &ndash; Acquires packets from network.</li>
<li>Decode and Stream Application layer &ndash; Decodes the data and handles TCP reassembly, etc.</li>
<li>Detection &ndash; Matches the decoded data against Rules.</li>
<li>Output &ndash; Deals with logging, and alerting.</li>
</ul>

<p>[Fig1]</p>

<p>Each thread can execute one or more thread module, depending on the runmode configuration.</p>

<h3 id="runmodes">Runmodes</h3>

<p>Suricata supports multiple runmodes to handle incoming packets:</p>

<ul>
<li>Single &ndash; Single-threaded mode.</li>
<li>AutoFP &ndash; The task of processing a packet is pipelined to multiple stages. Each thread handles one stage, and there is at least one thread in a stage.</li>
<li>Workers – Multiple workers, each of which single-handedly processes the packets it acquires (i.e., each thread runs all thread modules).</li>
</ul>

<p>We will introduce AutoFP and Workers modes in more detail.</p>

<h4 id="autofp-mode">AutoFP Mode</h4>

<p>In AutoFP mode, multiple threads try to acquire packets, and then put the packets to next stage of the pipeline for further processing. We refer to threads on packet acquisition stage as packet acquisition threads (PAQ), threads decoding packets as decoders, etc.</p>

<p>[Fig2]</p>

<h4 id="workers-mode">Workers Mode</h4>

<p>In &ldquo;workers&rdquo; mode, multiple threads can receive packets and the thread that receives the packet executes all thread modules to process the packet.</p>

<p>[Fig 3]</p>

<h4 id="single-mode">Single Mode</h4>

<p>Single mode is equivalent to workers mode with one worker thread.</p>

<h2 id="test-methodology">Test Methodology</h2>

<p>We rely on <a href="https://github.com/xybu/cs590-nfv">the test environment setup we made in NFV project</a>, and tweak the following parameters in the Suricata config:</p>

<ul>
<li>Runmode = {autofp, workers}</li>
<li>Number of (packet capture threads, decoding threads) = (1, 1) to (16, 32).</li>
<li>Number of NICs</li>
</ul>

<p>against various levels of workload generated by iperf (which turned out not doing well) and TCPreplay, and then collect performance and resource usage metrics. Suricata runs on bare metal.</p>

<h3 id="testbed-spec">Testbed Spec</h3>

<p>Both sender and receiver hosts have the following hardware spec:</p>

<ul>
<li>CPU: 2x Intel Xeon E5-2620 v4 @ 2.10GHz, 2 Sockets, 8 Cores Per Socket with HT disabled.</li>
<li>RAM: 64 GB</li>
<li>NICs: Intel I-350 Gigabit Ethernet</li>
</ul>

<p>and runs Ubuntu Server 16.04.2 LTS. The tests were based on Suricata 3.2, but there haven&rsquo;t been significant changes to its thread model as of Dec 2017.</p>

<h3 id="experiment-iperf">Experiment &ndash; iperf</h3>

<p>When using <a href="https://iperf.fr/">iperf</a>, we use multiple client-server pairs to generate traffic, which can be pure TCP or UDP packets. We also tweak packet size,  bandwidth, and number of parallel streams. Iperf server end runs on the same machine as Suricata, and one NIC can be used by one or more iperf pair.</p>

<p>[fig]</p>

<p>However, there is one issue with iperf approach. In order to compare the thread models of Suricata, we need controllable, constant packets-per-second (pps) workload to stress it.
And since packet payload does not matter much to Suricata and our NIC is 1Gbps, packets must be small. Due to TCP congestion control, pps from iperf varies greatly over time and is beyond our control.</p>

<p>Figure  shows the number of packets generated by iperf over time for one of the test runs.
 pps varies over time, but throughput (bps) is kept constant over this entire duration.
 This is done by increasing the packet size when the packet generation rate falls.</p>

<p>[fig]</p>

<p>Since pps generated by iperf is neither constant nor controllable over time, the total number of packets sent to Suricata for handling differs for each iteration of the same test. So we cannot guarantee all packet drops are due to Suricata, and data points generated by iperf cannot be used as a basis for comparison. We use TCPreplay to generate workload.</p>

<h3 id="experiment-tcpreplay">Experiment &ndash; TCPreplay</h3>

<p>TCPreplay replays a trace file onto a NIC notwithstanding network condition, so the behavior is reproducible across runs. We use an ISTS’12 trace, snort.log.1425823194, to generate the traffic. It generates 55.42 Mbps at 6264.04 pps for approx. 22 seconds. To generate higher workloads, up to 16 instances of TCPreplay per NIC are used. As a baseline, we verified that the testbed system is capable of handling peak workload of 16 TCPreplay instances without packet drop.
All reported drops therefore are caused by Suricata.</p>

<p>[fig]</p>

<h2 id="evaluating-performance-and-resource-usage">Evaluating Performance and Resource Usage</h2>

<p>The result is kind of surprising.</p>

<h3 id="results-autofp-mode">Results &ndash; AutoFP Mode</h3>

<h4 id="scalability-paqs-decoders">Scalability (#PAQs &lt;= #Decoders)</h4>

<p>Figure shows the comparison of Suricata performance, in terms of packets decoded vs. packets dropped, with 1 PAQ and 1, 2 and 4 decoders. It can be seen that performance does not scale with the number of decoders. This is also the case when 2 packet acquisition threads are used, as shown by Figure.</p>

<p>[Fig]</p>

<p>Comparing the two plots, we see that performance does not scale with the number of PAQ threads, either. Similar observations can be made from other data points.</p>

<p>[Fig]</p>

<h4 id="resource-usage">Resource Usage</h4>

<p>Figure shows the CPU usage and the number of packets processed by Suricata in autofp mode.
CPU usage increases linearly to the number of packet acquisition threads (PAQ), however, this does not translate to performance gain. RAM usage (not shown in the figure) increases sub-linearly and will not be a bottleneck.</p>

<p>[Fig]</p>

<h4 id="scalability-paqs-decoders-1">Scalability (#PAQs &gt;= #Decoders)</h4>

<p>Figure 9 compares Suricata performance with various number of PAQ threads (1,2,4,8) and multiple decoder threads (1,2). It can be seen that</p>

<ul>
<li>The performance does not scale with the number of packet acquisition threads or decode threads, and</li>
<li>CPU usage increases almost linearly with the number of PAQ threads, but it does not translate to performance.</li>
</ul>

<h4 id="multiple-nics">Multiple NICs</h4>

<p>Figure 10 shows the performance in autofp mode with 2 NICs. Suricata does not handle more packets even after multiple NICs are available.</p>

<h4 id="summary">Summary</h4>

<p>In all data points, we never see a speedup &gt; 1.13 (in terms of packets processed) for autofp mode.</p>

<h3 id="results-workers-mode">Results &ndash; Workers Mode</h3>

<p>Workers mode differs from autofp mode in that a packet, once captured, is never transferred to another thread for processing.</p>

<p>As seen from the graph, the performance decreases as the number of PAQ threads increases.</p>

<p>[Fig]</p>

<p>Figure 12 shows the performance comparison of worker mode with 1 and 2 packet decoding threads. It can be seen that the system performance does not scale with the number of PAQ threads.</p>

<p>[Fig]</p>

<p>Figure 13 shows the performance in worker mode with 2 NICs.</p>

<p>[Fig]</p>

<h4 id="summary-1">Summary</h4>

<p>Performance of the system does not increase significantly even after multiple NICs are available.
 In all the data points, the best speedup we see is 1.28 for workers mode.</p>

<h2 id="analyzing-runmodes-with-intel-vtune">Analyzing Runmodes with Intel vTune</h2>

<p>Intel vTune is a tool for software performance analysis. We used it to further analyze the unexpected result of Suricata thread models.</p>

<h3 id="autofp-mode-1">AutoFP Mode</h3>

<p>The analysis was based on running Suricata with 8 PAQ threads and 4 decoder
threads, 8X workload, and 2 NICs.</p>

<p>It confirmed what we observed from the experiment that AutoFP mode has higher
level of concurrency compared to Workers mode. The average CPU usage is ~1000%.
However, recall that the performance does not improve even though more resource
is used.</p>

<p><img src="/images/suricata-thread-model/vtune_suricata_autofp_thread_concurrency.png" alt="Suricata shows low degree of concurrency in autofp mode." /></p>

<h4 id="contentions">Contentions</h4>

<p>With the help of Locks and Waits analysis of Intel vTune, we see that the
majority of CPU resource is spent on <code>poll()</code>. The second point of contention
is a condition variable to receive packets from the queue.</p>

<p>This is also reflected in the lower part of the screenshot. The 16 PAQ threads
(&ldquo;RX&rdquo; threads) are busy polling I/O events. And the load is not balanced in
neither PAQ threads nor decoder threads.</p>

<p><img src="/images/suricata-thread-model/vtune_suricata_autofp_contentions.png" alt="Threads shows high level of contentions in autofp mode." /></p>

<h4 id="busy-paq-threads">Busy PAQ Threads</h4>

<h3 id="workers-mode-1">Workers Mode</h3>

<p>Intel vTune confirmed that Workers mode had poor degree of thread concurrency
and barely used more than two cores during its execution. The following
screenshots are from analyzing Suricata with 8 workers, 8X workload, and 2 NICs.
Note that Suricata creates 8 workers for each NIC, so there are 16 workers in
total.</p>

<p><img src="/images/suricata-thread-model/vtune_suricata_workers_thread_concurrency.png" alt="Suricata shows low degree of concurrency in workers mode." /></p>

<h4 id="contentions-1">Contentions</h4>

<p>We see that the mutex to control fetching flows from hash is a major point of
contention. About 300 seconds out of ~360 seconds’ execution is spent here.
Besides, the load among the 16 workers (8 workers per NIC) is highly
imbalanced, even though the TCPreplay processes provide same load.</p>

<p><img src="/images/suricata-thread-model/vtune_suricata_workers_imbalanced_load.png" alt="The workload is highly imbalanced among workers." /></p>

<h2 id="conclusion">Conclusion</h2>

<p>While more threads lead to higher resource usage (particularly in autofp mode),
they do not translate into higher performance. From what we observed, neither
multi-thread modes of Suricata scale to the number of available cores:</p>

<ul>
<li><p>AutoFP mode (Speedup &lt;= 1.13)</p>

<ul>
<li>Trivial to no speedup with increased number of PAQ or decoder threads.</li>
<li>Exhibits linear CPU usage increase, however, by wasting most of CPU cycles in polling.</li>
</ul></li>

<li><p>Workers mode (Speedup &lt;= 1.28)</p>

<ul>
<li>Exhibits worse performance than AutoFP mode but uses less resource.</li>
<li>Hardly uses more than two CPU cores due to mutex contention.</li>
</ul></li>
</ul>

<p>And neither modes scale to the number of NICs.</p>

<p>The multi-thread design does not give Suricata the scalability it wants, nor
give it performance advantage over single-threaded Snort. To improve
performance, Suricata should rethink its thread model and reduce contentions
as much as possible.</p>

    
</div>

    
    
    <div class="tags">
        <i class="fa fa-tags"></i>
        
            <a href="/tags/purdue">purdue</a>
        
            <a href="/tags/networking">networking</a>
        
            <a href="/tags/project">project</a>
        
            <a href="/tags/suricata">suricata</a>
        
            <a href="/tags/benchmark">benchmark</a>
        
    </div>
    


</article>

        
    </div>

    <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "xbu" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

     

        </div>

        <footer>
    <div class="container">
        <div class="recent-posts">
            <strong>Latest posts</strong>
                <ul>
                
                    <li>
                        <a href="/article/performance-characterization-of-suricata-thread-models/">Performance Characterization of Suricata&#39;s Thread Models</a>
                    </li>
                
                    <li>
                        <a href="/article/benchmarking-suricata-in-different-isolation-systems-using-tcpreplay/">Benchmarking Suricata in Different Isolation Systems Using TCPreplay</a>
                    </li>
                
                    <li>
                        <a href="/link/hack-font/">Hack Font</a>
                    </li>
                
                    <li>
                        <a href="/quote/andy-grove-paranoid/">Only the Paranoid Survive</a>
                    </li>
                
                    <li>
                        <a href="/article/onedrived/">onedrived - Microsoft OneDrive client for Linux</a>
                    </li>
                
                    <li>
                        <a href="/article/gitlab-ag/">gitlab-ag - Combining Git and Autograding</a>
                    </li>
                
                    <li>
                        <a href="/gallery/stockpulse-wp8/">StockPulse for WP8 - a StockTwits client for WP8</a>
                    </li>
                
                </ul>
        </div>

        <div class="categories">
            <strong>Categories</strong>

            
                <ul>
                
                    <li>
                        <a href="/categories/hack">Hack (1)</a>
                    </li>
                
                    <li>
                        <a href="/categories/project">Project (8)</a>
                    </li>
                
                    <li>
                        <a href="/categories/resource">Resource (4)</a>
                    </li>
                
                    <li>
                        <a href="/categories/troubleshooting">Troubleshooting (1)</a>
                    </li>
                
                    <li>
                        <a href="/categories/tutorial">Tutorial (2)</a>
                    </li>
                
                </ul>
            
        </div>

        <div class="social-media">
            <strong>Social media</strong>

            
                <a href="https://www.facebook.com/xiangyu.bu" target="_blank"><i class="fa fa-facebook"></i></a>
            
            
            
            
            
                <a href="https://www.instagram.com/xybu92/" target="_blank"><i class="fa fa-instagram"></i></a>
            
            
            
            
            
                <a href="https://github.com/xybu" target="_blank"><i class="fa fa-github"></i></a>
            
            
                <a href="https://bitbucket.org/xybu/" target="_blank"><i class="fa fa-bitbucket"></i></a>
            
        </div>
    </div>
</footer>

<div class="credits">
    <div class="container">
        <div class="copyright">
             &copy; 2017 Xiangyu Bu. <br />
            Unless otherwise noted, licensed under <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0 License</a>.
        </div>
        <div class="author">
            Theme by <a href="https://github.com/Lednerb/bilberry-hugo-theme" target="_blank">Lednerb</a>
        </div>
    </div>
</div>


        
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-47913300-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>


        
        
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$','$'], ['\\(','\\)']]}
        });
</script>

        

        <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.19.1/moment-with-locales.min.js" integrity="sha256-TbOIe++NbC9P3KTtUMJ5wcROlBdnRqrPleLdpPg3xxE=" crossorigin="anonymous"></script>
        <script src="/dist/theme.js"></script>

        <script>
            $(document).ready(function() {
                $(".moment").each(function() {
                    $(this).text(
                        moment( $(this).text() )
                            .locale( "en" )
                            .format('LL')
                    );
                });

                $(".footnote-return sup").html("[return]")
            })
        </script>

        
            
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.29.0/autocomplete.jquery.min.js" integrity="sha256-qUqrH6CxKeU+3ClSSiq0GGnYjoKmfLhNO4tFoTCay5c=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/algoliasearch/3.24.5/algoliasearch.min.js" integrity="sha256-vUvLcn3X0cXhote4PNwW6d+fzjJR0hoD+yGFeVaElew=" crossorigin="anonymous"></script>

<script>
    var client = algoliasearch("QWH90AJ7UA", "2b55d53047105f6dd3e8d30f7aadc3e9");
    var index = client.initIndex("xbu_me_index");

    $('#search').autocomplete({ hint: false, autoselect: true, debug: false },
      [
        {
          source: $.fn.autocomplete.sources.hits(index, { hitsPerPage: 5 }),
          displayKey: function(suggestion) {
            return suggestion.title || suggestion.author
          },
          templates: {
            suggestion: function(suggestion) {
                return "<span class='entry " + suggestion.type + "'>"
                      + "<span class='title'>" + suggestion.title + "</span>"
                      + "<span class='fa fa-fw " + suggestion.iconClass + "'></span>"
                  + "</span>"
                ;
            },
            empty: function() {
              return "<span class='empty'>Nothing found.</span>"
            },
            footer: function() {
              return '<div class="branding">Powered by <img src="https://www.algolia.com/static_assets/images/press/downloads/algolia-logo-light.svg" /></div>'
            }

          },
        }
      ])
      .on('autocomplete:selected', function(event, suggestion, dataset) {
        window.location = (suggestion.url);
      })
      .keypress(function (event, suggestion) {
        if (event.which == 13) {
          window.location = (suggestion.url);
        }
      });
</script>

        


    </body>
</html>
